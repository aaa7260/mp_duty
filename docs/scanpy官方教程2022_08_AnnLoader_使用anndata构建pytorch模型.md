---
title: "scanpy官方教程2022|08-AnnLoader：使用anndata构建pytorch模型"
date: 2022-10-11T14:15:21Z
draft: ["false"]
tags: [
  "fetched",
  "单细胞天地"
]
categories: ["Acdemic"]
---
scanpy官方教程2022|08-AnnLoader：使用anndata构建pytorch模型 by 单细胞天地
------
<div><section data-style-type="5" data-tools="新媒体排版" data-id="2430070"><section data-style-type="5" data-tools="新媒体排版" data-id="2390348"><section><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><section><section><br></section><section><section><section powered-by="xiumi.us"><section><section><p>分享是一种态度</p></section></section></section></section></section></section></section></section><section><section powered-by="xiumi.us"><section><section><img data-ratio="0.8738095" data-src="https://mmbiz.qpic.cn/mmbiz_gif/siaia0BDGJdjSnnb9ibXpFagGPWQ0JjSSTNVBZthROEhicfINuLcxX2Ro3Zb600LJhrzeYIb120tLjSVXEtLn14DwA/640?wx_fmt=gif" data-type="gif" data-w="420" width="100%" src="https://mmbiz.qpic.cn/mmbiz_gif/siaia0BDGJdjSnnb9ibXpFagGPWQ0JjSSTNVBZthROEhicfINuLcxX2Ro3Zb600LJhrzeYIb120tLjSVXEtLn14DwA/640?wx_fmt=gif"></section></section></section></section></section></section></section></section></section><section data-tool="mdnice编辑器" data-website="https://www.mdnice.com"><blockquote data-tool="mdnice编辑器"><p>学习资料来源：</p><ul><li><section>anndata主页：https://anndata-tutorials.readthedocs.io/en/latest/index.html</section></li><li><section>官网：https://anndata-tutorials.readthedocs.io/en/latest/annloader.html【注意教程有两个版本，这里是latest版本的学习笔记】</section></li></ul></blockquote><p data-tool="mdnice编辑器">本教程展示了如何使用AnnLoader来利用anndata构建pytorch模型，<span>进行单细胞数据中批次的矫正</span>。</p><ul data-tool="mdnice编辑器"><li><section>检查用pytorch构建接口的很好的替代方法，例如<span>scvi-tools</span><sup>[1]</sup></section></li><li><section>在这里，我们使用<span>Pyro</span><sup>[2]</sup>框架来简化变异自动解码器(a Variational Autoencoder)的代码</section></li></ul><p data-tool="mdnice编辑器">那此教程可能需要简单理解一下什么是pytorch：https://blog.csdn.net/ljx1400052550/article/details/110005062</p><p data-tool="mdnice编辑器">简而言之：<span>pytorch是一个深度学习框架，可以使用pytorch搭建自己的模型</span></p><h2 data-tool="mdnice编辑器"><span></span><span>首先，加载各种包</span></h2><p data-tool="mdnice编辑器">其中pyro这个包的安装可参考：http://pyro.ai/</p><pre data-tool="mdnice编辑器"><span></span><code><span>import</span> gdown<br><span>import</span> torch<br><span>import</span> torch.nn <span>as</span> nn<br><span>import</span> pyro<br><span>import</span> pyro.distributions <span>as</span> dist<br><span>import</span> numpy <span>as</span> np<br><span>import</span> scanpy <span>as</span> sc<br><span>from</span> sklearn.preprocessing <span>import</span> OneHotEncoder, LabelEncoder<br><span>from</span> anndata.experimental.pytorch <span>import</span> AnnLoader<br><span>import</span> matplotlib.pyplot <span>as</span> plt<br></code></pre><h2 data-tool="mdnice编辑器"><span></span><span>VAE 模型定义</span></h2><p data-tool="mdnice编辑器">这里我们定义了一个辅助多层感知器类，以便在下面的VAE中使用</p><p data-tool="mdnice编辑器">Note：这段代码在复制的时候最好放在vscode中，python有严格的代码缩进要求，不然可能会报错。</p><pre data-tool="mdnice编辑器"><span></span><code><span><span>class</span> <span>MLP</span><span>(nn.Module)</span>:</span><br>    <span><span>def</span> <span>__init__</span><span>(self, input_dim, hidden_dims, out_dim)</span>:</span><br>        super().__init__()<br>        modules = []<br>        <span>for</span> in_size, out_size <span>in</span> zip([input_dim]+hidden_dims, hidden_dims):<br>            modules.append(nn.Linear(in_size, out_size))<br>            modules.append(nn.LayerNorm(out_size))<br>            modules.append(nn.ReLU())<br>            modules.append(nn.Dropout(p=<span>0.05</span>))<br>        modules.append(nn.Linear(hidden_dims[<span>-1</span>], out_dim))<br>        self.fc = nn.Sequential(*modules)<br>    <span><span>def</span> <span>forward</span><span>(self, *inputs)</span>:</span><br>        input_cat = torch.cat(inputs, dim=<span>-1</span>)<br>        <span>return</span> self.fc(input_cat)<br></code></pre><p data-tool="mdnice编辑器">下面显示了VAE模型的图形表示。它使用未观察到的潜变量Z和观察到的批次标签batch重构输入数据X和分类标签class。注意，该模型将Class视为来自给定Z的X的自变量。</p><figure data-tool="mdnice编辑器"><img data-ratio="0.3459715639810427" data-src="https://mmbiz.qpic.cn/mmbiz_png/siaia0BDGJdjTIpFUCRgB2VMG8ylJwPuSY5kfFuduycvQH4gWsQ1A8FjVjdTcMh6hiaibctLyJdocDUYJrQxw4WmjA/640?wx_fmt=png" data-type="png" data-w="844" src="https://mmbiz.qpic.cn/mmbiz_png/siaia0BDGJdjTIpFUCRgB2VMG8ylJwPuSY5kfFuduycvQH4gWsQ1A8FjVjdTcMh6hiaibctLyJdocDUYJrQxw4WmjA/640?wx_fmt=png"></figure><p data-tool="mdnice编辑器">在这里我们定义了我们的模型，请参阅Pyro VAE教程了解更多细节。</p><pre data-tool="mdnice编辑器"><span></span><code><span><span>class</span> <span>CVAE</span><span>(nn.Module)</span>:</span><br>    <span># The code is based on the scarches trVAE model</span><br>    <span># https://github.com/theislab/scarches/blob/v0.3.5/scarches/models/trvae/trvae.py</span><br>    <span># and on the pyro.ai Variational Autoencoders tutorial</span><br>    <span># http://pyro.ai/examples/vae.html</span><br>    <span><span>def</span> <span>__init__</span><span>(self, input_dim, n_conds, n_classes, hidden_dims, latent_dim)</span>:</span><br>        super().__init__()<br>        self.encoder = MLP(input_dim+n_conds, hidden_dims, <span>2</span>*latent_dim) <span># output - mean and logvar of z</span><br>        self.decoder = MLP(latent_dim+n_conds, hidden_dims[::<span>-1</span>], input_dim)<br>        self.theta = nn.Linear(n_conds, input_dim, bias=<span>False</span>)<br>        self.classifier = nn.Linear(latent_dim, n_classes)<br>        self.latent_dim = latent_dim<br>    <span><span>def</span> <span>model</span><span>(self, x, batches, classes, size_factors)</span>:</span><br>        pyro.module(<span>"cvae"</span>, self)<br>        batch_size = x.shape[<span>0</span>]<br>        <span>with</span> pyro.plate(<span>"data"</span>, batch_size):<br>            z_loc = x.new_zeros((batch_size, self.latent_dim))<br>            z_scale = x.new_ones((batch_size, self.latent_dim))<br>            z = pyro.sample(<span>"latent"</span>, dist.Normal(z_loc, z_scale).to_event(<span>1</span>))<br>            classes_probs = self.classifier(z).softmax(dim=<span>-1</span>)<br>            pyro.sample(<span>"class"</span>, dist.Categorical(probs=classes_probs), obs=classes)<br>            dec_mu = self.decoder(z, batches).softmax(dim=<span>-1</span>) * size_factors[:, <span>None</span>]<br>            dec_theta = torch.exp(self.theta(batches))<br>            logits = (dec_mu + <span>1e-6</span>).log() - (dec_theta + <span>1e-6</span>).log()<br>            pyro.sample(<span>"obs"</span>, dist.NegativeBinomial(total_count=dec_theta, logits=logits).to_event(<span>1</span>), obs=x.int())<br>    <span><span>def</span> <span>guide</span><span>(self, x, batches, classes, size_factors)</span>:</span><br>        batch_size = x.shape[<span>0</span>]<br>        <span>with</span> pyro.plate(<span>"data"</span>, batch_size):<br>            z_loc_scale = self.encoder(x, batches)<br>            z_mu = z_loc_scale[:, :self.latent_dim]<br>            z_var = torch.sqrt(torch.exp(z_loc_scale[:, self.latent_dim:]) + <span>1e-4</span>)<br>            pyro.sample(<span>"latent"</span>, dist.Normal(z_mu, z_var).to_event(<span>1</span>)) <br><br></code></pre><h2 data-tool="mdnice编辑器"><span></span><span>AnnLoader初始化</span></h2><p data-tool="mdnice编辑器">首先，下载数据</p><p data-tool="mdnice编辑器">链接需要访问谷歌，我自己单独使用魔法进行了下载，到本地。</p><p data-tool="mdnice编辑器">数据包括15681个细胞，1000个基因</p><pre data-tool="mdnice编辑器"><span></span><code>url = <span>'https://drive.google.com/uc?id=1ehxgfHTsMZXy6YzlFKGJOsBKQ5rrvMnd'</span><br>dir = <span>'/Pub/Users/project/scanpy/pytorch/'</span><br>output = dir + <span>'pancreas.h5ad'</span><br>gdown.download(url, output, quiet=<span>False</span>)<br><br><span># 读取数据</span><br>adata = sc.read(dir + <span>'pancreas_normalized.h5ad'</span>)<br>adata<br><br><span># AnnData object with n_obs × n_vars = 15681 × 1000</span><br><span>#     obs: 'batch', 'study', 'cell_type', 'size_factors'</span><br></code></pre><p data-tool="mdnice编辑器">通过Scanpy流程使用UMAP可视化数据。</p><pre data-tool="mdnice编辑器"><span></span><code>sc.pp.neighbors(adata)<br>sc.tl.umap(adata)<br>sc.pl.umap(adata, color=[<span>'study'</span>, <span>'cell_type'</span>], wspace=<span>0.35</span>)<br>plt.savefig(dir + <span>"01-UMAP.png"</span>)<br></code></pre><p data-tool="mdnice编辑器">结果图如下：我们可以看到数据具有很强的批处理效应，来自不同的数据集。我们想用我们的VAE模型来整合这些批次</p><figure data-tool="mdnice编辑器"><img data-ratio="0.2671541057367829" data-src="https://mmbiz.qpic.cn/mmbiz_png/siaia0BDGJdjTIpFUCRgB2VMG8ylJwPuSYB3BC6RcmIVQBse6wYttFd6lIBdnBUic0p894eJWSph8mrnR20u4eohg/640?wx_fmt=png" data-type="png" data-w="1778" src="https://mmbiz.qpic.cn/mmbiz_png/siaia0BDGJdjTIpFUCRgB2VMG8ylJwPuSYB3BC6RcmIVQBse6wYttFd6lIBdnBUic0p894eJWSph8mrnR20u4eohg/640?wx_fmt=png"></figure><p data-tool="mdnice编辑器">对于我们的模型，我们需要每个细胞的大小因子(库大小)作为负二项式重构loss的均值。</p><pre data-tool="mdnice编辑器"><span></span><code><span># put raw counts to .X</span><br>adata.X = adata.raw.X <br>adata.obs[<span>'size_factors'</span>] = adata.X.sum(<span>1</span>)<br></code></pre><p data-tool="mdnice编辑器">在这里，我们为AnnData对象中的标签设置编码器。当在训练阶段从数据加载器访问标签时，AnnLoader将使用这些编码器动态地转换标签。</p><pre data-tool="mdnice编辑器"><span></span><code>adata.obs[<span>'study'</span>].cat.categories<br><br>encoder_study = OneHotEncoder(sparse=<span>False</span>, dtype=np.float32)<br>encoder_study.fit(adata.obs[<span>'study'</span>].to_numpy()[:, <span>None</span>])<br><br>adata.obs[<span>'cell_type'</span>].cat.categories<br><br>encoder_celltype = LabelEncoder()<br>encoder_celltype.fit(adata.obs[<span>'cell_type'</span>])<br><br>use_cuda = torch.cuda.is_available()<br></code></pre><p data-tool="mdnice编辑器">可以使用函数或函数的映射创建转换器，这些函数将应用于属性的值(<code>.obs</code>，<code>.obsm</code>，<code>.layers</code>，<code>.x</code>)或子集对象中这些属性的特定键。指定一个属性和一个键(如果需要)作为传递的Mapping的键，并指定一个函数作为值应用。</p><p data-tool="mdnice编辑器">这里我们定义了一个转换器，它将使用上面创建的编码器转换<code>.obs</code>的<code>'study'</code>和<code>'cell_type'</code>键的值.</p><pre data-tool="mdnice编辑器"><span></span><code>encoders = {<br>    <span>'obs'</span>: {<br>        <span>'study'</span>: <span>lambda</span> s: encoder_study.transform(s.to_numpy()[:, <span>None</span>]),<br>        <span>'cell_type'</span>: encoder_celltype.transform<br>    }<br>}<br></code></pre><p data-tool="mdnice编辑器">这里我们创建了一个AnnLoader对象，它将返回一个为我们的AnnData对象正确设置的PyTorch数据加载器.</p><p data-tool="mdnice编辑器"><code>use_cuda</code>参数表示我们想要惰性转换AnnData对象中的所有数值。所谓惰性转换，是指在访问数据之前，数据不会被转换。AnnLoader对象从提供的AnnData对象创建了一个包装器对象，它负责子集设置和转换。这里不会复制完整的AnnData对象。</p><p data-tool="mdnice编辑器">在将任何内容发送到Cuda之前，将应用传递给<code>convert</code>的编码器。</p><pre data-tool="mdnice编辑器"><span></span><code>dataloader = AnnLoader(adata, batch_size=<span>128</span>, shuffle=<span>True</span>, convert=encoders, use_cuda=use_cuda)<br></code></pre><p data-tool="mdnice编辑器">这就是上面提到的包装器对象。数据加载器遍历该对象：</p><pre data-tool="mdnice编辑器"><span></span><code>dataloader.dataset<br><span># AnnCollection object with n_obs × n_vars = 15681 × 1000</span><br><span>#   constructed from 1 AnnData objects</span><br><span>#     view of obsm: 'X_pca', 'X_umap'</span><br><span>#     obs: 'batch', 'study', 'cell_type', 'size_factors'</span><br></code></pre><p data-tool="mdnice编辑器">注意：如果<code>use_cuda=True</code>，那么所有数值都将转换为tensors并发送给cuda，因此在训练阶段不需要做任何转换。</p><p data-tool="mdnice编辑器"><code>view of obsm</code>意味着包装器对象不会从基础AnnData对象的.obm复制任何内容。<code>obs</code>insted of <code>view of obs</code>意味着该对象从AnnData对象复制了.obs。</p><pre data-tool="mdnice编辑器"><span></span><code>dataloader.dataset[:<span>10</span>]<br><span># AnnCollectionView object with n_obs × n_vars = 10 × 1000</span><br><span>#     obsm: 'X_pca', 'X_umap'</span><br><span>#     obs: 'batch', 'study', 'cell_type', 'size_factors'</span><br></code></pre><p data-tool="mdnice编辑器">note:子集中的数值已经被转换并发送给cuda(如果需要)。</p><pre data-tool="mdnice编辑器"><span></span><code>batch = dataloader.dataset[:<span>10</span>]<br><br>print(<span>'X:'</span>, batch.X.device, batch.X.dtype)<br>print(<span>'X_pca:'</span>, batch.obsm[<span>'X_pca'</span>].device, batch.obsm[<span>'X_pca'</span>].dtype)<br>print(<span>'X_umap:'</span>, batch.obsm[<span>'X_umap'</span>].device, batch.obsm[<span>'X_umap'</span>].dtype)<br><span># and here you can see that the converters are applied to 'study' and 'cell_type'.</span><br>print(<span>'study:'</span>, batch.obs[<span>'study'</span>].device, batch.obs[<span>'study'</span>].dtype)<br>print(<span>'cell_type:'</span>, batch.obs[<span>'cell_type'</span>].device, batch.obs[<span>'cell_type'</span>].dtype)<br><br><span>#X: cuda:0 torch.float32</span><br><span>#X_pca: cuda:0 torch.float32</span><br><span>#X_umap: cuda:0 torch.float32</span><br><span>#study: cuda:0 torch.float32</span><br><span>#cell_type: cuda:0 torch.int32</span><br></code></pre><p data-tool="mdnice编辑器">还可以使用自定义sampler，而不是AnnLoader中的。只需传递<code>sampler</code>和<code>batch_size</code>即可。</p><pre data-tool="mdnice编辑器"><span></span><code><span>from</span> torch.utils.data <span>import</span> WeightedRandomSampler<br>weights = np.ones(adata.n_obs)<br>weights[adata.obs[<span>'cell_type'</span>] == <span>'Pancreas Stellate'</span>] = <span>2.</span><br>sampler = WeightedRandomSampler(weights, adata.n_obs)<br>dataloader = AnnLoader(adata, batch_size=<span>128</span>, sampler=sampler, convert=encoders, use_cuda=use_cuda)<br></code></pre><p data-tool="mdnice编辑器">我们不使用自定义采样器来训练模型，所以这里返回到默认采样器:</p><pre data-tool="mdnice编辑器"><span></span><code>dataloader = AnnLoader(adata, batch_size=<span>128</span>, shuffle=<span>True</span>, convert=encoders, use_cuda=use_cuda)<br></code></pre><h2 data-tool="mdnice编辑器"><span></span><span>初始化和训练模型</span></h2><p data-tool="mdnice编辑器">在这里，我们初始化模型和Pyro例程以进行训练。</p><pre data-tool="mdnice编辑器"><span></span><code>n_conds = len(adata.obs[<span>'study'</span>].cat.categories)<br>n_classes = len(adata.obs[<span>'cell_type'</span>].cat.categories)<br>cvae = CVAE(adata.n_vars, n_conds=n_conds, n_classes=n_classes, hidden_dims=[<span>128</span>, <span>128</span>], latent_dim=<span>10</span>)<br><br><span>if</span> use_cuda:<br>    cvae.cuda()<br>    <br>optimizer = pyro.optim.Adam({<span>"lr"</span>: <span>1e-3</span>})<br>svi = pyro.infer.SVI(cvae.model, cvae.guide, optimizer, loss=pyro.infer.TraceMeanField_ELBO())<br></code></pre><p data-tool="mdnice编辑器">注意，现在可以简单地从数据加载器中获取batch，选择所需的属性，在需要时对其进行处理并传递给loss函数。所有内容都已由预定义的转换器转换。你不需要复制你的AnnData对象，也不需要为所需键的字典定制数据加载器，所有的观察键都已经在bacthes中了。</p><pre data-tool="mdnice编辑器"><span></span><code><span><span>def</span> <span>train</span><span>(svi, train_loader)</span>:</span><br>    epoch_loss = <span>0.</span><br>    <span>for</span> batch <span>in</span> train_loader:<br>        epoch_loss += svi.step(batch.X, batch.obs[<span>'study'</span>], batch.obs[<span>'cell_type'</span>], batch.obs[<span>'size_factors'</span>])<br>    normalizer_train = len(train_loader.dataset)<br>    total_epoch_loss_train = epoch_loss / normalizer_train<br>    <span>return</span> total_epoch_loss_train<br><br>NUM_EPOCHS = <span>210</span><br><br><span>for</span> epoch <span>in</span> range(NUM_EPOCHS):<br>    total_epoch_loss_train = train(svi, dataloader)<br>    <span>if</span> epoch % <span>40</span> == <span>0</span> <span>or</span> epoch == NUM_EPOCHS<span>-1</span>:<br>        print(<span>"[epoch %03d]  average training loss: %.4f"</span> % (epoch, total_epoch_loss_train))<br></code></pre><p data-tool="mdnice编辑器">这里运行时间比较久，运行日志：</p><pre data-tool="mdnice编辑器"><span></span><code>[epoch <span>000</span>]  average training loss: <span>1236.4254</span><br>[epoch <span>040</span>]  average training loss: <span>697.7242</span><br>[epoch <span>080</span>]  average training loss: <span>687.5900</span><br>[epoch <span>120</span>]  average training loss: <span>684.3700</span><br>[epoch <span>160</span>]  average training loss: <span>682.2220</span><br>[epoch <span>200</span>]  average training loss: <span>681.1151</span><br>[epoch <span>209</span>]  average training loss: <span>681.0516</span><br><br></code></pre><h2 data-tool="mdnice编辑器"><span></span><span>检查结果</span></h2><pre data-tool="mdnice编辑器"><span></span><code><span># No copies yet, nothing is copied until you access specific attributes (.X, .obsm etc.).</span><br>full_data = dataloader.dataset[:] <br><br><span># get mean values of the latent variables</span><br>means = cvae.encoder(full_data.X, full_data.obs[<span>'study'</span>])[:, :<span>10</span>] <br><br>adata.obsm[<span>'X_cvae'</span>] = means.data.cpu().numpy()<br>sc.pp.neighbors(adata, use_rep=<span>'X_cvae'</span>)<br>sc.tl.umap(adata)<br>sc.pl.umap(adata, color=[<span>'study'</span>, <span>'cell_type'</span>], wspace=<span>0.35</span>)<br>plt.savefig(dir + <span>"02-UMAP_integration.png"</span>)<br></code></pre><p data-tool="mdnice编辑器">使用VAE 模型整合后的结果：整合后，可以看到下面右图中相同细胞类型都聚在了一起。</p><figure data-tool="mdnice编辑器"><img data-ratio="0.28940731399747793" data-src="https://mmbiz.qpic.cn/mmbiz_png/siaia0BDGJdjTIpFUCRgB2VMG8ylJwPuSYSkao9hk56r6IgR7ibdibUibrAic6EicIVq3ca83umOfSnYttCLTuYsrAtgA/640?wx_fmt=png" data-type="png" data-w="1586" src="https://mmbiz.qpic.cn/mmbiz_png/siaia0BDGJdjTIpFUCRgB2VMG8ylJwPuSYSkao9hk56r6IgR7ibdibUibrAic6EicIVq3ca83umOfSnYttCLTuYsrAtgA/640?wx_fmt=png"></figure><p data-tool="mdnice编辑器">准确性：</p><pre data-tool="mdnice编辑器"><span></span><code>accuracy = (cvae.classifier(means).argmax(dim=<span>-1</span>)==full_data.obs[<span>'cell_type'</span>]).sum().item()/adata.n_obs<br>accuracy<br><br><span># 0.9195204387475289</span><br></code></pre><p data-tool="mdnice编辑器">下次见~</p><hr><h3 data-tool="mdnice编辑器"><span>参考资料</span></h3><section data-tool="mdnice编辑器"><span><span>[1]</span><p>scvi-tools: <em>https://scvi-tools.org/</em></p></span><span><span>[2]</span><p>Pyro: <em>http://pyro.ai/</em></p></span></section></section><section><section data-style-type="5" data-tools="新媒体排版" data-id="2440476"><section><section><section><section><img data-ratio="0.9495798319327731" data-src="https://mmbiz.qpic.cn/mmbiz_gif/09gp6SvPE04j3m2v7Hr889icHUyibTOHs8YuUibicl7ibRD0ZwG5pDTjBluRreZvuib1o3BibvLkicYhnA4YW7dQsjn0cA/640?wx_fmt=gif" data-type="gif" data-w="119" data-width="100%" src="https://mmbiz.qpic.cn/mmbiz_gif/09gp6SvPE04j3m2v7Hr889icHUyibTOHs8YuUibicl7ibRD0ZwG5pDTjBluRreZvuib1o3BibvLkicYhnA4YW7dQsjn0cA/640?wx_fmt=gif"></section><section data-brushtype="text">往期回顾</section><section><br></section></section></section></section><section><section data-autoskip="1"><p><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzI1Njk4ODE0MQ==&amp;mid=2247508218&amp;idx=1&amp;sn=4f9278873d00d4a6e18b1b0501b0687d&amp;chksm=ea1ca678dd6b2f6ed670cece0fb652a00573863fcd02ffc29ab01f221e99cb954ffd4410f37c&amp;scene=21#wechat_redirect" textvalue="人—心肌梗塞的空间多组学图谱" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span>人—心肌梗塞的空间多组学图谱</span></a><br></p><p><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzI1Njk4ODE0MQ==&amp;mid=2247508199&amp;idx=1&amp;sn=692f03da0c5ffd721bc838e4376c8bd9&amp;chksm=ea1ca665dd6b2f73b7472f2dd2844c3077df290aea48501b6546b12d0150657ab71c5c0f7355&amp;scene=21#wechat_redirect" textvalue="内皮细胞细分亚群" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span>内皮细胞细分亚群</span></a><br></p><p><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzI1Njk4ODE0MQ==&amp;mid=2247508185&amp;idx=1&amp;sn=8f390f47fb7142beced128754e8cc40e&amp;chksm=ea1ca65bdd6b2f4d130ffc7a50e878750d6a01bd5a62f9a578182927990e04876d41fe329f52&amp;scene=21#wechat_redirect" textvalue="Python图文复现2022|06-单细胞功能富集分析" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span>Python图文复现2022|06-单细胞功能富集分析</span></a><br></p><p><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzI1Njk4ODE0MQ==&amp;mid=2247507932&amp;idx=1&amp;sn=4834a6dca7e832b058e811b55f038a78&amp;chksm=ea1cd95edd6b50485f2c1655acce47c6d3f5c4185af84e1ee35abe9be1e9ba4898b64031967c&amp;scene=21#wechat_redirect" textvalue="如何看两分组单细胞亚群比例差异？" linktype="text" imgurl="" imgdata="null" data-itemshowtype="11" tab="innerlink" data-linktype="2"><span>如何看两分组单细胞亚群比例差异？</span></a><br></p><p><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzI1Njk4ODE0MQ==&amp;mid=2247507930&amp;idx=1&amp;sn=20f24108ea33dc10a57f86074602c3e1&amp;chksm=ea1cd958dd6b504e6052d44ad1a2f4f3e495735c390a96b1d7224d7c80fc9f10a8dda4a7639b&amp;scene=21#wechat_redirect" textvalue="流式细胞筛选可以达到什么程度的纯呢？" linktype="text" imgurl="" imgdata="null" data-itemshowtype="11" tab="innerlink" data-linktype="2"><span>流式细胞筛选可以达到什么程度的纯呢？</span></a><br></p></section></section><hr><p><br></p></section><section data-style-type="5" data-tools="新媒体排版" data-id="2440475"><hr><p><br></p><hr><section><p>如果你对单细胞转录组研究感兴趣，但又不知道如何入门，也许你可以关注一下下面的课程<span></span></p><p><br></p><ul><li><p><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzI1Njk4ODE0MQ==&amp;mid=2247505898&amp;idx=1&amp;sn=3caaa355db327f412fe27c969f20533c&amp;chksm=ea1cd168dd6b587e7c955c80a87b78248f4fe7cf88514caf7fdca580e98877d4e2d96e40dcb7&amp;scene=21#wechat_redirect" textvalue="提前锁定年后马拉松授课名额，赠送价值1600的单细胞数据分析一次" linktype="text" imgurl="" imgdata="null" data-itemshowtype="11" tab="innerlink" data-linktype="2" hasload="1">提前锁定年后马拉松授课名额，赠送价值1600的单细胞数据分析一次</a><br></p></li><li><p><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzI1Njk4ODE0MQ==&amp;mid=2247501306&amp;idx=1&amp;sn=a38c5d2c3665ec0949649f22a8c7cd72&amp;chksm=ea1cc378dd6b4a6e1cdb72babea1fb4b232810c7656ac81963175e735a8d10a7cfae73921a16&amp;scene=21#wechat_redirect" textvalue="一个10x单细胞样品费用拿下你的专属64线程200G内存服务器" linktype="text" imgurl="" imgdata="null" data-itemshowtype="11" tab="innerlink" data-linktype="2" wah-hotarea="click" hasload="1">一个10x单细胞样品费用拿下你的专属64线程200G内存服务器</a></p></li><li><p><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzI1Njk4ODE0MQ==&amp;mid=2247501306&amp;idx=3&amp;sn=64ad5b7771462b946c74733d6e184f5e&amp;chksm=ea1cc378dd6b4a6ef6af8f0751e29c7180a7c69a96c54a94cb6163bc1d4b11daee2893102d53&amp;scene=21#wechat_redirect" textvalue="96线程384G内存服务器共享一年仅700（每月一批，循环开通账号）" linktype="text" imgurl="" imgdata="null" data-itemshowtype="11" tab="innerlink" data-linktype="2" wah-hotarea="click" hasload="1">96线程384G内存服务器共享一年仅700（每月一批，循环开通账号）</a></p></li></ul><p><img data-ratio="1" data-src="https://mmbiz.qpic.cn/mmbiz_gif/4TKeL1ZejtlKxOib5kmKX6ic6eX0w0WK5jvhtz9yBRsO3OI4yr6S5iaLNM7AbAeuPDHXMvDdur2DRz9wyiax4lEviag/640?wx_fmt=gif" data-type="gif" data-w="240" src="https://mmbiz.qpic.cn/mmbiz_gif/4TKeL1ZejtlKxOib5kmKX6ic6eX0w0WK5jvhtz9yBRsO3OI4yr6S5iaLNM7AbAeuPDHXMvDdur2DRz9wyiax4lEviag/640?wx_fmt=gif"><br></p><p><img data-ratio="0.05278592375366569" data-src="https://mmbiz.qpic.cn/mmbiz/4TKeL1Zejtlq03ZOSZiaTlic1MxgdKiaxTbOZ7ZSe0Xx1Ca8xF3L6Nyj1FYUajtYrSmRIHyZVSsAve0EAvEicZONpg/640?wx_fmt=jpeg" data-type="other" data-w="341" src="https://mmbiz.qpic.cn/mmbiz/4TKeL1Zejtlq03ZOSZiaTlic1MxgdKiaxTbOZ7ZSe0Xx1Ca8xF3L6Nyj1FYUajtYrSmRIHyZVSsAve0EAvEicZONpg/640?wx_fmt=jpeg"></p><p><strong><span>看完记得顺手点个</span></strong><span><strong><span>“在看”</span></strong></span><strong><span>哦！</span></strong></p></section><section><section data-id="93668"><section><section data-width="95%"><section><section><section data-width="38%"><section><section data-tools="135编辑器" data-id="93668"><section><section data-width="95%"><section><section><section data-width="61.8%"><section><section><section><p><br></p><span><strong data-burshtype="text"><img data-copyright="0" data-cropselx1="0" data-cropselx2="109" data-cropsely1="0" data-cropsely2="109" data-ratio="1" data-src="https://mmbiz.qpic.cn/mmbiz/siaia0BDGJdjRMGrkqo64BGKecYk4akuHpGHVQs7FeOpY7eWbIPGC1tRw5Tw0oEPmx053mR9FTVerWvhuZchIpZw/640?wx_fmt=jpeg" data-type="other" data-w="430" title="qrcode_for_gh_5a3c482ed99f_1280.jpg" src="https://mmbiz.qpic.cn/mmbiz/siaia0BDGJdjRMGrkqo64BGKecYk4akuHpGHVQs7FeOpY7eWbIPGC1tRw5Tw0oEPmx053mR9FTVerWvhuZchIpZw/640?wx_fmt=jpeg"><strong data-burshtype="text">生物</strong><strong data-burshtype="text"> | 单细胞 | 转录组丨资料</strong></strong></span></section><section><span><strong data-burshtype="text">每天都精彩</strong></span></section></section></section><section><section><section><section><section><section><p><span>长按扫码可关注</span></p></section></section></section></section></section></section></section></section></section></section></section></section></section></section></section></section></section></section></section></section></section></section><p><mp-style-type data-value="3"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/-WI1NAnFqjAndFZWIYuEgQ",target="_blank" rel="noopener noreferrer">原文链接</a>
