---
title: "在Mac和Windows装GPU版的Pytorch"
date: 2023-04-05T04:56:17Z
draft: ["false"]
tags: [
  "fetched",
  "洲更的第二大脑"
]
categories: ["Acdemic"]
---
在Mac和Windows装GPU版的Pytorch by 洲更的第二大脑
------
<div><section data-tool="mdnice编辑器" data-website="https://www.mdnice.com"><p data-tool="mdnice编辑器">Pytorch是目前最火的深度学习框架之一，另一个是TensorFlow。不过我之前一直用到是CPU版本，几个月前买了一台3070Ti的笔记本（是的，我在40系显卡出来的时候，买了30系，这确实一言难尽），同时我也有一台M1芯片Macbook Pro，目前也支持了pytorch的GPU加速，所以我就想着，在这两个电脑上装个Pytorch，浅度学习深度学习。</p><h2 data-tool="mdnice编辑器"><span></span><span>Apple silicon</span></h2><p data-tool="mdnice编辑器">首先是M1芯片，这个就特别简单了。先装一个conda，只不过是内置mamba包管理器，添加conda-forge频道，arm64版本。</p><pre data-tool="mdnice编辑器"><span></span><code><span># 下载</span><br>wget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-MacOSX-arm64.sh<br><span># 安装</span><br>bash Mambaforge-MacOSX-arm64.sh<br></code></pre><p data-tool="mdnice编辑器">然后我们用mamba创建一个环境，用的是开发版的pytorch，所以频道指定pytorch-nightly</p><pre data-tool="mdnice编辑器"><span></span><code>mamba create -n pytorch \<br>   jupyterlab jupyterhub pytorch torchvision torchaudio <br>   -c pytorch-nightly<br></code></pre><p data-tool="mdnice编辑器">最后，用<code>conda activate pytorch</code>,然后测试是否正确识别到GPU</p><pre data-tool="mdnice编辑器"><span></span><code>import torch<br>torch.has_mps<br><span># True</span><br><span># 配置device</span><br>device = torch.device(<span>"mps"</span>)<br></code></pre><p data-tool="mdnice编辑器">参考资料: https://developer.apple.com/metal/pytorch/</p><h2 data-tool="mdnice编辑器"><span></span><span>Windows NVIDIA</span></h2><p data-tool="mdnice编辑器">首先，需要确保你的电脑安装的是NVIDIA的显卡，以及有了相应的CUDA驱动。</p><blockquote data-tool="mdnice编辑器"><p>CUDA的显卡架构要求: https://docs.nvidia.com/deeplearning/cudnn/support-matrix/index.html</p></blockquote><p data-tool="mdnice编辑器">新一代的电脑上基本都自带CUDA驱动。可以通过打开NVIDIA控制面板的系统信息</p><figure data-tool="mdnice编辑器"><img data-ratio="0.7398148148148148" data-src="https://mmbiz.qpic.cn/mmbiz_png/hiaSZLAw0jibSrIBUfrsVRI6Ox7yibJweKpicaGKyNmQLb5yoszbtuvhHqB5xicdibpa3DU4kXJzpwfTZJB0Pu7DBcOQ/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/hiaSZLAw0jibSrIBUfrsVRI6Ox7yibJweKpicaGKyNmQLb5yoszbtuvhHqB5xicdibpa3DU4kXJzpwfTZJB0Pu7DBcOQ/640?wx_fmt=png"><figcaption>image.png</figcaption></figure><p data-tool="mdnice编辑器">在组件中查看你已经安装的CUDA驱动，例如我的是11.7.89 。</p><figure data-tool="mdnice编辑器"><img data-ratio="0.9094567404426559" data-src="https://mmbiz.qpic.cn/mmbiz_png/hiaSZLAw0jibSrIBUfrsVRI6Ox7yibJweKpdDnBjvJcT9TmxIl3VRKAvxmIpR1NDk1kdQRiaHibIeSLnQvUFv4ic0zkg/640?wx_fmt=png" data-type="png" data-w="994" src="https://mmbiz.qpic.cn/mmbiz_png/hiaSZLAw0jibSrIBUfrsVRI6Ox7yibJweKpdDnBjvJcT9TmxIl3VRKAvxmIpR1NDk1kdQRiaHibIeSLnQvUFv4ic0zkg/640?wx_fmt=png"><figcaption>image.png</figcaption></figure><p data-tool="mdnice编辑器">也可以通过命令行的方式查看，</p><figure data-tool="mdnice编辑器"><img data-ratio="0.5166666666666667" data-src="https://mmbiz.qpic.cn/mmbiz_png/hiaSZLAw0jibSrIBUfrsVRI6Ox7yibJweKpicCwuqv6w0l0EX6KSBKvo9jpn6Sohw4dicODGNKKNgK1uQEL0s3c688A/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/hiaSZLAw0jibSrIBUfrsVRI6Ox7yibJweKpicCwuqv6w0l0EX6KSBKvo9jpn6Sohw4dicODGNKKNgK1uQEL0s3c688A/640?wx_fmt=png"><figcaption>image.png</figcaption></figure><p data-tool="mdnice编辑器">接下来，我们来安装pytorch。同样也是推荐conda的方法，我们先从清华镜像源中下载Miniconda。</p><figure data-tool="mdnice编辑器"><img data-ratio="0.3888888888888889" data-src="https://mmbiz.qpic.cn/mmbiz_png/hiaSZLAw0jibSrIBUfrsVRI6Ox7yibJweKp58jl0voVslqxqiciah0xoyy2Bz3YAp2ZsZdYXCN5iatBUHQqdicYIKxyhA/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/hiaSZLAw0jibSrIBUfrsVRI6Ox7yibJweKp58jl0voVslqxqiciah0xoyy2Bz3YAp2ZsZdYXCN5iatBUHQqdicYIKxyhA/640?wx_fmt=png"><figcaption>image.png</figcaption></figure><p data-tool="mdnice编辑器">选择Windows的安装包</p><figure data-tool="mdnice编辑器"><img data-ratio="0.4666666666666667" data-src="https://mmbiz.qpic.cn/mmbiz_png/hiaSZLAw0jibSrIBUfrsVRI6Ox7yibJweKpn1SicNuy0WvXD6Yg2LBwJmDBfic9fSulIS4L93w4NMgIcicgzm9EBkTgg/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/hiaSZLAw0jibSrIBUfrsVRI6Ox7yibJweKpn1SicNuy0WvXD6Yg2LBwJmDBfic9fSulIS4L93w4NMgIcicgzm9EBkTgg/640?wx_fmt=png"><figcaption>image.png</figcaption></figure><p data-tool="mdnice编辑器">安装完之后，我们就可以通过Anaconda Prompt进入命令行，根据pytorch网站上的推荐进行安装。</p><figure data-tool="mdnice编辑器"><img data-ratio="0.39166666666666666" data-src="https://mmbiz.qpic.cn/mmbiz_png/hiaSZLAw0jibSrIBUfrsVRI6Ox7yibJweKp4d2FwcgYJRZlpib1iapjGJz3o6OWXK8wl7x3XibRhfBNvY9QZwiawpDPMQ/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/hiaSZLAw0jibSrIBUfrsVRI6Ox7yibJweKp4d2FwcgYJRZlpib1iapjGJz3o6OWXK8wl7x3XibRhfBNvY9QZwiawpDPMQ/640?wx_fmt=png"><figcaption>image.png</figcaption></figure><p data-tool="mdnice编辑器">但是有一点不同，为了避免环境冲突，最好是单独创建一个环境，所以代码如下</p><pre data-tool="mdnice编辑器"><span></span><code>conda create -n pytorch pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia<br></code></pre><p data-tool="mdnice编辑器">接着用 <code>conda activate pytorch</code>启动环境，然后在python环境中测试</p><pre data-tool="mdnice编辑器"><span></span><code><span>import</span> torch<br>torch.has_cuda<br><span># True</span><br></code></pre><p data-tool="mdnice编辑器">几个常见的问题（至少我在写文章想到的问题）：</p><p data-tool="mdnice编辑器">Q: 使用conda和pip安装的区别是什么？</p><p data-tool="mdnice编辑器">A: conda是pytorch官方推荐的安装方式，因为conda会一并帮你装好pytorch运行所需要的CUDA驱动和相关工具集。这意味着为conda所占用的空间会更多一些。</p><p data-tool="mdnice编辑器">Q: 可以在非常老的硬件上安装最新的pytorch吗？</p><p data-tool="mdnice编辑器">A: 我觉得这个跟装游戏类似，你虽然能装上游戏，但是不满足游戏的最低配置需求，照样跑不动。</p><p data-tool="mdnice编辑器">Q: 电脑上必须要安装CUDA驱动和安装CUDA toolkit吗？</p><p data-tool="mdnice编辑器">A: 其实我个人不是很确定如何回答，如下是我目前的一些见解。如果你用的conda，那么他会帮你解决一些依赖问题。如果你是用pip，那么就需要你自己动手配置。其中，CUDA驱动是必须要安装的，因为CUDA驱动负责将GPU硬件与计算机操作系统相连接，不装驱动，操作系统就不识别CUDA核心，相当你没装NVIDIA显卡。而CUDA toolkit是方便我们调用CUDA核心的各种开发工具集合，你装CUDA toolkit的同时会配套安装CUDA驱动。除非你要做底层开发，或者你需要从源码编译一个pytorch，否则我们大可不装CUDA toolkit。</p><p data-tool="mdnice编辑器">Q: 如果我电脑上的CUDA驱动版本比较旧怎么办？或者说我CUDA的驱动版本是11.7，但是我安装了cuda=11.8的pytorch，或者版本不一样的pytorch会怎么样？</p><p data-tool="mdnice编辑器">A: 我们在安装cuda=11.7的pytorch，本质上安装的是在CUDA Toolkit版本为11.7环境下编译好的pytorch版本。当cuda版本之间的差异不是特别的大，或者说不是破坏性的升级的情况下，那么理论上也是能运行的。</p><h2 data-tool="mdnice编辑器"><span></span><span>手写数据性能测试</span></h2><p data-tool="mdnice编辑器">下面用的是GPT3.5给我提供一段手写字识别（MNIST)案例代码，用来测试不同的平台的速度。</p><pre data-tool="mdnice编辑器"><span></span><code><span>import</span> torch<br><span>import</span> torchvision<br><span>import</span> torchvision.transforms <span>as</span> transforms<br><br><span># 转换数据格式并且加载数据</span><br>transform = transforms.Compose(<br>    [transforms.ToTensor(),<br>     transforms.Normalize((<span>0.5</span>,), (<span>0.5</span>,))])<br><br>trainset = torchvision.datasets.MNIST(root=<span>'./data'</span>, train=<span>True</span>,<br>                                        download=<span>True</span>, transform=transform)<br>trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span>64</span>,<br>                                          shuffle=<span>True</span>, num_workers=<span>2</span>)<br><br>testset = torchvision.datasets.MNIST(root=<span>'./data'</span>, train=<span>False</span>,<br>                                       download=<span>False</span>, transform=transform)<br>testloader = torch.utils.data.DataLoader(testset, batch_size=<span>64</span>,<br>                                         shuffle=<span>False</span>, num_workers=<span>2</span>)<br><br><span># 定义网络模型</span><br><span><span>class</span> <span>Net</span><span>(torch.nn.Module)</span>:</span><br>    <span><span>def</span> <span>__init__</span><span>(self)</span>:</span><br>        super(Net, self).__init__()<br>        self.conv1 = torch.nn.Conv2d(<span>1</span>, <span>6</span>, <span>5</span>)<br>        self.pool = torch.nn.MaxPool2d(<span>2</span>, <span>2</span>)<br>        self.conv2 = torch.nn.Conv2d(<span>6</span>, <span>16</span>, <span>5</span>)<br>        self.fc1 = torch.nn.Linear(<span>16</span> * <span>4</span> * <span>4</span>, <span>120</span>)<br>        self.fc2 = torch.nn.Linear(<span>120</span>, <span>84</span>)<br>        self.fc3 = torch.nn.Linear(<span>84</span>, <span>10</span>)<br><br>    <span><span>def</span> <span>forward</span><span>(self, x)</span>:</span><br>        x = self.pool(torch.nn.functional.relu(self.conv1(x)))<br>        x = self.pool(torch.nn.functional.relu(self.conv2(x)))<br>        x = x.view(<span>-1</span>, <span>16</span> * <span>4</span> * <span>4</span>)<br>        x = torch.nn.functional.relu(self.fc1(x))<br>        x = torch.nn.functional.relu(self.fc2(x))<br>        x = self.fc3(x)<br>        <span>return</span> x<br><br>net = Net()<br><br><span># 这里的代码比较随意，就是用哪个平台运行哪个</span><br><span># CPU</span><br>device = torch.device(<span>"cpu"</span>)<br><span># CUDA</span><br>device = torch.device(<span>"cuda:0"</span>)<br><span># MPS</span><br>device = torch.device(<span>"mps"</span>)<br><br>net.to(device)<br><br><span># 定义损失函数和优化器</span><br>criterion = torch.nn.CrossEntropyLoss()<br>optimizer = torch.optim.SGD(net.parameters(), lr=<span>0.001</span>, momentum=<span>0.9</span>)<br><br><span># 训练网络</span><br><br><span>import</span> time<br><br>start_time = time.time()  <span># 记录开始时间</span><br><br><span>for</span> epoch <span>in</span> range(<span>10</span>):  <span># 进行10次迭代训练</span><br>    running_loss = <span>0.0</span><br>    <span>for</span> i, data <span>in</span> enumerate(trainloader, <span>0</span>):<br>        inputs, labels = data[<span>0</span>].to(device), data[<span>1</span>].to(device)<br>        optimizer.zero_grad()<br>        outputs = net(inputs)<br>        loss = criterion(outputs, labels)<br>        loss.backward()<br>        optimizer.step()<br><br>        running_loss += loss.item()<br>        <span>if</span> i % <span>100</span> == <span>99</span>:<br>            print(<span>'[%d, %5d] loss: %.3f'</span> %<br>                  (epoch + <span>1</span>, i + <span>1</span>, running_loss / <span>100</span>))<br>            running_loss = <span>0.0</span><br><br>end_time = time.time()  <span># 记录结束时间</span><br>training_time = end_time - start_time  <span># 计算训练时间</span><br><br>print(<span>'Training took %.2f seconds.'</span> % training_time)<br><br>print(<span>'Finished Training'</span>)<br><br><span># 测试网络</span><br>correct = <span>0</span><br>total = <span>0</span><br><span>with</span> torch.no_grad():<br>    <span>for</span> data <span>in</span> testloader:<br>        images, labels = data[<span>0</span>].to(device), data[<span>1</span>].to(device)<br>        outputs = net(images)<br>        _, predicted = torch.max(outputs.data, <span>1</span>)<br>        total += labels.size(<span>0</span>)<br>        correct += (predicted == labels).sum().item()<br><br>print(<span>'Accuracy of the network on the 10000 test images: %d %%'</span> % (<br>      ))<br><br></code></pre><p data-tool="mdnice编辑器">最后统计下来的结果为</p><p data-tool="mdnice编辑器">Windows平台</p><ul data-tool="mdnice编辑器"><li><section>3070Ti Training took 45.02 seconds.</section></li><li><section>i9 12900H Training took CPU 75.65</section></li></ul><p data-tool="mdnice编辑器">Mac平台</p><ul data-tool="mdnice编辑器"><li><section>M1 Max Training took 50.79 seconds.</section></li><li><section>M1 MAX CPU Training took 109.61 seconds.</section></li></ul><p data-tool="mdnice编辑器">总体上来说，GPU加速很明显，无论是mac还是Windows。其次是GPU加速效果对比，M1 max芯片比3070Ti差个10%？。</p><p data-tool="mdnice编辑器">不过目前测试都是小数据集，等我学一段时间，试试大数据集的效果。</p></section><p><br></p><p><mp-style-type data-value="3"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/eoaiBk6DcO1LjAIJqqBRsQ",target="_blank" rel="noopener noreferrer">原文链接</a>
