---
title: "GEO数据库的多个表达量数据集的整合分析方法（表达量芯片和转录组测序）"
date: 2024-04-22T23:53:12Z
draft: ["false"]
tags: [
  "fetched",
  "生信菜鸟团"
]
categories: ["Acdemic"]
---
GEO数据库的多个表达量数据集的整合分析方法（表达量芯片和转录组测序） by 生信菜鸟团
------
<div><section data-tool="mdnice编辑器" data-website="https://www.mdnice.com"><p data-tool="mdnice编辑器">      <span>在进行数据挖掘的时候，我们往往会筛选到不止一个符合我们预期的数据集，这些数据集来源于不同的研究人员。<strong>这样得到的这些数据集就会存在我们所谓的批次效应，如不同实验时间、不同实验批次、不同处理方法、不同测序平台等。</strong>遇到这一情况，我们该如何选择数据和处理数据呢？如果我们只选择一个数据集进行分析，貌似有点不太能说明其他研究人员的研究结果，但如果把所有符合我们实验目标的数据集都能拿来分析又有点无从下手。这里，我们就来介绍一下面对多个GEO数据集，我们该怎么处理？</span></p><p data-tool="mdnice编辑器"><span>       首先，我们要明确一点，符合我们实验目标的数据集能搜集多少，尽可能的都用上，因为单独数据集的分析存在部分实验误差，不具有代表性。其次，针对多个数据集，我们可以有两种思路来进行整合分析：</span><span><strong>一是，合并和去除这些批次效应；二是，对各数据集分别进行处理，然后求交集，获得共有结果。</strong></span></p><p data-tool="mdnice编辑器"><strong>一、合并并去除批次效应</strong></p><p data-tool="mdnice编辑器">    <span>  在GEO数据集合并和去除批次校正方法的方法主要包括ComBat方法（parametric prior method，ComBat_p和non-parametric method，ComBat_n）、代理变量法（Surrogate variable analysis，SVA）、基于比值的方法（Geometric ratio-based method，Ratio_G）、平均中心方法（Mean-centering，PAMR）和距离加权判别（Distance-weighted discrimination，DWD）方法。综合多种指标认为ComBat在精确性、准确性和整体性能方面（precision, accuracy and overall performance）总体优于其他方法。R中的SVA包中有ComBat和ComBat_seq函数可以用来校正批次效应，输入数据为干净的、标准化的表达数据（如FPKM、TPM等），通常是芯片数据。</span></p><p data-tool="mdnice编辑器"><span><strong>代码示例如下</strong></span></p><pre data-tool="mdnice编辑器"><code><span># 导入数据集1</span><br>data1 &lt;- read.csv(<span>"PRJNA423456_FPKM.csv"</span>, header = TRUE) <span>#这里的数据集为模拟数据集，大家改成自己的数据集进行分析</span><br><span># 导入数据集2</span><br>data2 &lt;- read.csv(<span>"PRJNA777728_FPKM.csv"</span>, header = TRUE) <span>#这里的数据集为模拟数据集，大家改成自己的数据集进行分析</span><br><span># 导入数据集3</span><br>data3 &lt;- read.csv(<span>"PRJNA6878999_FPKM.csv"</span>, header = TRUE) <span>#这里的数据集为模拟数据集，大家改成自己的数据集进行分析</span><br><span># 导入数据集4</span><br>data4 &lt;- read.csv(<span>"PRJNA590000_FPKM.csv"</span>, header = TRUE) <span>#这里的数据集为模拟数据集，大家改成自己的数据集进行分析</span><br><span>#### 合并数据集</span><br>library(<span>"sva"</span>) <span>#没有软件的话请先安装软件</span><br>library(<span>"tidyverse"</span>) <span>#没有软件的话请先安装软件</span><br>merge_eset1 &lt;- inner_join(data1, data2, by = <span>"Gene.ID"</span>, suffix = c(<span>".data1"</span>, <span>".data2"</span>)) <span>#X是第一列名，需要将基因名放在第一列而不是成为行名</span><br>merge_eset1 <br>merge_eset2 &lt;- inner_join(data3, data4, by = <span>"Gene.ID"</span>, suffix = c(<span>".data3"</span>, <span>".data4"</span>))<br>merge_eset &lt;- inner_join(merge_eset1, merge_eset2, by = <span>"Gene.ID"</span>, suffix = c(<span>".merge_eset1"</span>, <span>".merge_eset2"</span>))<br>merge_eset<br>rownames(merge_eset) &lt;- merge_eset<span>$Gene</span>.ID<br>merge_eset &lt;- merge_eset[,-1]  <span>#把第一列基因名放为行名</span><br>dim(merge_eset)    <span>#查看数据维度</span><br>exp &lt;- as.matrix(merge_eset)<br>dimnames &lt;- list(rownames(exp),colnames(exp))<br>data &lt;- matrix(as.numeric(as.matrix(exp)),nrow=nrow(exp),dimnames=dimnames)<br>dim(data)<br>class(data) <span>#返回"matrix" "array"</span><br>write.csv(data,<span>"mrna_nocombat.csv"</span>)<br><span>#过滤掉低表达的基因</span><br>Expr &lt;- data[rowSums(data)&gt;1,]<br>Expr=log2(Expr+1)<br><br><span>#PCA分析可视化个数据集在去批次前的聚簇效果</span><br><span># 这里我们先获取分组信息</span><br>group_list &lt;- data.frame(<br>  sample = colnames(exp_all), c(rep(<span>"PRJNAX423456_A"</span>,3),rep(<span>"PRJNA423456_B"</span>,3),rep(<span>"PRJNA777728_A"</span>,3),rep(<span>"PRJNA777728_C"</span>,3),<br>                                rep(<span>"PRJNA777728_B"</span>,3),rep(<span>"PRJNA6878999_A"</span>,10),rep(<span>"PRJNA6878999_B"</span>,9),rep(<span>"PRJNA590000_A"</span>,3),rep(<span>"PRJNA590000_C"</span>,3),<br>                                rep(<span>"PRJNA590000_B"</span>,3)))<br>rownames(group_list) &lt;- group_list<span>$sample</span><br>colnames(group_list)[2] &lt;- <span>"dataset"</span><br>group &lt;- factor(group_list<span>$dataset</span>)<br>View(group_list)<br><span>##载入样品信息，含批次</span><br>data2 &lt;- read.csv(<span>"All_data.csv"</span>,header = T)<br>data2[,2] &lt;- as.factor(data2<span>$Type</span> )<span>##type表示的是生物学上的不同处理</span><br>data2[,3] &lt;- as.factor(data2<span>$Batch</span> )<span>##batch表示不同的批次信息</span><br>row.names(data2) &lt;- data2<span>$Sample</span><br>View(data2)<br>data2<br><br>library(FactoMineR)<span>##没有请先安装</span><br>library(factoextra)<br>pdf(file = <span>"PCA_before1.pdf"</span>,width = 7,height = 6)<br>pre.pca &lt;- PCA(t(exp_all),graph = FALSE)<br>fviz_pca_ind(pre.pca,<br>             geom= <span>"point"</span>,<br>             col.ind = data2<span>$Batch</span>,<br>             addEllipses = TRUE,<br>             legend.title=<span>"Group"</span><br>              )<br>dev.off()<br><br></code></pre><figure data-tool="mdnice编辑器"><img data-imgfileid="100037931" data-ratio="0.9134860050890585" data-src="https://mmbiz.qpic.cn/mmbiz_png/iaRJcrq2Los9dNjEH4oku8kBKGStVDVN8IicLlx49eCvHM0Q5CsheNRK0YXpG5fNBT7BcEkYzpIQq2qeZs6Yj6Og/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="393" src="https://mmbiz.qpic.cn/mmbiz_png/iaRJcrq2Los9dNjEH4oku8kBKGStVDVN8IicLlx49eCvHM0Q5CsheNRK0YXpG5fNBT7BcEkYzpIQq2qeZs6Yj6Og/640?wx_fmt=png&amp;from=appmsg"></figure><pre data-tool="mdnice编辑器"><code><span>#-------------------进行去批次------------------#</span><br><span>#### 使用sva包计算批次效应</span><br>library(sva)<br>exp_all_combat &lt;- ComBat(exp_all, batch = group_list<span>$dataset</span>) <span># batch为批次信息</span><br><span># 查看去除批次效应的结果如何</span><br>library(tinyarray)<br>draw_pca(exp = exp_all_combat, group_list = group)<br><br><span>#做校正的PCA分析</span><br>pdf(file = <span>"9_PCA_after.pdf"</span>,width = 7,height = 6)<br>pre.pca &lt;- PCA(t(exp_all_combat),graph = FALSE)<br>fviz_pca_ind(pre.pca,<br>             geom= <span>"point"</span>,<br>             col.ind = data2<span>$Batch</span>,<br>             addEllipses = TRUE,<br>             legend.title=<span>"Group"</span>)<br>dev.off()<br><br></code></pre><figure data-tool="mdnice编辑器"><img data-imgfileid="100037930" data-ratio="0.9153674832962138" data-src="https://mmbiz.qpic.cn/mmbiz_png/iaRJcrq2Los9dNjEH4oku8kBKGStVDVN8mapuo3rrfXeMBx8Cib5wlSyRsDNHCJJuLricGlMIvhscvJyNqKe6kyDQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="449" src="https://mmbiz.qpic.cn/mmbiz_png/iaRJcrq2Los9dNjEH4oku8kBKGStVDVN8mapuo3rrfXeMBx8Cib5wlSyRsDNHCJJuLricGlMIvhscvJyNqKe6kyDQ/640?wx_fmt=png&amp;from=appmsg"></figure><p data-tool="mdnice编辑器">      值得注意的是，去批次效应处理后，个别基因的表达量会出现负数，这个时候用我们常规的edgeR和DEseq2进行差异分析是行不通的。而且上述我们使用FPKM值做的去除批次效应，所以在进行差异分析时，不可使用edgeR和DEseq2，但是可以用limma包进行差异分析。对于WGCNA的分析，似乎不受影响。</p><p data-tool="mdnice编辑器"><strong>二、整合数据及分析</strong></p><p data-tool="mdnice编辑器">      在数据挖掘过程中，我们同时会分析多个数据集的表达谱数据，这样就会都得到多个差异分析列表。那么，怎么样才能挑出一些更重要的或者更有生物学意义的基因进行后续实验呢？常规做法就是将三个数据集的差异基因列表进行overlapping，但这种方法只考虑到了gene出现的次数，并没有考虑到基因在多个差<span>异</span>分列表中排序上的重要性。</p><p data-tool="mdnice编辑器">      Robust Rank Aggregation(RRA)方法则可以对对多个排好序的基因集进行求交集，同时还考虑一下它们的排序情况。总体上来说，就是挑选那些在多个数据集都表现差异的基因，并且每次差异都排名靠前的那些，他们的最终综合排名也会比较靠前。</p><p data-tool="mdnice编辑器"><span><strong>代码示例如下</strong></span></p><pre data-tool="mdnice编辑器"><code>setwd(<span>"F:\\RRA分析-2024-03-29\\4_RRA分析-2\\Anagen_Catagen"</span>)<br><span>#1.读入GSE数据集</span><br>files=c(<span>"PRJNA590000_A_C.DESeq2.csv"</span>,<br>        <span>"PRJNA779755_A_C.DESeq2.csv"</span>)<br>upList=list()<br>downList=list()<br>allFCList=list()<br><span>for</span>(i <span>in</span> 1:length(files)){<br>  inputFile=files[i]<br>  rt=read.csv(inputFile)<br>  header=unlist(strsplit(inputFile,<span>"_"</span>))<br>  downList[[header[1]]]=as.vector(rt[,1]) <br>  upList[[header[1]]]=rev(as.vector(rt[,1]))<br>  fcCol=rt[,1:2]   colnames(fcCol)=c(<span>"Gene"</span>,header[[1]]) <br>  allFCList[[header[1]]]=fcCol <br>}<br>View(allFCList)<br><br><span>#2.合并所有的FC值</span><br>mergeLe=<span>function</span>(x,y){<br>  merge(x,y,by=<span>"Gene"</span>,all=FALSE)}<br>newTab=Reduce(mergeLe,allFCList)<br>View(newTab)<br>rownames(newTab)=newTab[,1]<br>newTab=newTab[,2:ncol(newTab)]<br>newTab[is.na(newTab)]=0<br>dim(newTab)<br><br><span>#3.获取上调基因</span><br>library(RobustRankAggreg)<br>upMatrix = rankMatrix(upList)<br>View(upMatrix)<br>dim(upMatrix)<br>upAR = aggregateRanks(rmat=upMatrix)<br>View(upAR)<br>dim(upAR)<br>colnames(upAR)=c(<span>"Name"</span>,<span>"Pvalue"</span>)<br>upAdj=p.adjust(upAR<span>$Pvalue</span>,method=<span>"bonferroni"</span>)<br><span>#help(p.adjust)</span><br>upXls=cbind(upAR,adjPvalue=upAdj)<br>upFC=newTab[as.vector(upXls[,1]),]<br>upXls=cbind(upXls,logFC=rowMeans(upFC))<br>write.table(upXls,file=<span>"up.xls"</span>,sep=<span>"\t"</span>,quote=F,row.names=F)<br>upSig=upXls[(upXls<span>$Pvalue</span>&lt;0.01 &amp; upXls<span>$logFC</span>&gt; log2(2)),]<br>dim(upSig)<br>write.table(upSig,file=<span>"upSig_2.xls"</span>,sep=<span>"\t"</span>,quote=F,row.names=F)<br><span>#3.获取下调基因</span><br>downMatrix = rankMatrix(downList)<br>downAR = aggregateRanks(rmat=downMatrix)<br>colnames(downAR)=c(<span>"Name"</span>,<span>"Pvalue"</span>)<br>downAdj=p.adjust(downAR<span>$Pvalue</span>,method=<span>"BH"</span>)<br>downXls=cbind(downAR,adjPvalue=downAdj)<br>downFC=newTab[as.vector(downXls[,1]),]<br>downXls=cbind(downXls,logFC=rowMeans(downFC))<br>write.table(downXls,file=<span>"down.xls"</span>,sep=<span>"\t"</span>,quote=F,row.names=F)<br>downSig=downXls[(downXls<span>$Pvalue</span>&lt;0.01 &amp; downXls<span>$logFC</span>&lt; -log2(2)),]<br>dim(downSig)<br>write.table(downSig,file=<span>"downSig_2.xls"</span>,sep=<span>"\t"</span>,quote=F,row.names=F)<br><span>#整合上下调基因</span><br>allSig = rbind(upSig,downSig)<br>colnames(allSig)<br>allSig = allSig[,c(<span>"Name"</span>,<span>"logFC"</span>)]<br>View(allSig)<br>write.table(allSig,file = <span>'allSign_2.xls'</span>,sep = <span>'\t'</span>,quote = F)<br><span>#显示排名靠前的前20个上下调基因的结果logFC.tiff</span><br>hminput=newTab[c(as.vector(upSig[1:20,1]),as.vector(downSig[c(1:20),1])),]<br>library(pheatmap)<br>tiff(file=<span>"logFC2_1_2.tiff"</span>,width = 15,height = 20,units =<span>"cm"</span>,compression=<span>"lzw"</span>,<span>bg</span>=<span>"white"</span>,res=400)<br>pheatmap(hminput,display_numbers = TRUE,fontsize_row=10,fontsize_col=12,<br>         color = colorRampPalette(c(<span>"blue"</span>,<span>"white"</span>, <span>"red"</span>))(200),<br>         cluster_cols = FALSE,cluster_rows = FALSE, angle_col = 45)<br>dev.off()<br><br></code></pre><figure data-tool="mdnice编辑器"><img data-imgfileid="100037932" data-ratio="1.2966101694915255" data-src="https://mmbiz.qpic.cn/mmbiz_png/iaRJcrq2Los9dNjEH4oku8kBKGStVDVN8309pbEiaicTvic4j3AES4tbj4DKiatJ8JpS7giclwutKdf040XfqXicBbVibg/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="708" src="https://mmbiz.qpic.cn/mmbiz_png/iaRJcrq2Los9dNjEH4oku8kBKGStVDVN8309pbEiaicTvic4j3AES4tbj4DKiatJ8JpS7giclwutKdf040XfqXicBbVibg/640?wx_fmt=png&amp;from=appmsg"></figure><p data-tool="mdnice编辑器">      目前最常用的整合分析方法即为以上所介绍的两种方法，最后给大家放置几篇相关参考文献以供借鉴！</p><ol data-tool="mdnice编辑器"><li><section><p><span>Xing J, Chen M, Han Y. Multiple datasets to explore the tumor microenvironment of cutaneous squamous cell carcinoma. Math Biosci Eng. 2022 Apr 8;19(6):5905-5924. doi: 10.3934/mbe.2022276. <strong>IF: 2.6 Q2</strong>. PMID: 35603384. https://pubmed.ncbi.nlm.nih.gov/35603384/</span></p></section></li><li><section><p><span>Li Z, Li X, Jin M, Liu Y, He Y, Jia N, Cui X, Liu Y, Hu G, Yu Q. Identification of potential biomarkers and their correlation with immune infiltration cells in schizophrenia using combinative bioinformatics strategy. Psychiatry Res. 2022 Aug;314:114658. doi: 10.1016/j.psychres.2022.114658. <strong>IF: 11.3 Q1</strong>. https://pubmed.ncbi.nlm.nih.gov/35660966/</span></p></section></li><li><section><p><span>Mo M, Liu B, Luo Y, Tan JHJ, Zeng X, Zeng X, Huang D, Li C, Liu S, Qiu X. Construction and Comprehensive Analysis of a circRNA-miRNA-mRNA Regulatory Network to Reveal the Pathogenesis of Hepatocellular Carcinoma. Front Mol Biosci. 2022 Jan 24;9:801478. doi: 10.3389/fmolb.2022.801478. <strong>IF: 5.0 Q2</strong>. https://pubmed.ncbi.nlm.nih.gov/35141281/</span></p></section></li></ol></section><h3 data-tool="mdnice编辑器"><span>文末友情宣传</span></h3><p data-tool="mdnice编辑器"><strong>强烈建议你推荐给身边的博士后以及年轻生物学PI，多一点数据认知，让他们的科研上一个台阶：</strong></p><ul data-tool="mdnice编辑器"><li><section><a href="https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;mid=2247529099&amp;idx=1&amp;sn=fe3be2d43a6284a36c15625c23dc9a3e&amp;scene=21#wechat_redirect" data-linktype="2">生物信息学马拉松授课（买一得五）</a> ，你的生物信息学入门课</section></li><li><section><a href="https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;mid=2247524148&amp;idx=1&amp;sn=7806da6feb41a36493c519c1cfc1d3ac&amp;scene=21#wechat_redirect" data-linktype="2">时隔5年，我们的生信技能树VIP学徒继续招生啦</a></section></li><li><section><a href="https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;mid=2247528363&amp;idx=1&amp;sn=5e02f3e9b2e148191e23ebc2c0d780e7&amp;scene=21#wechat_redirect" data-linktype="2">2024的共享服务器交个朋友福利价仍然是800</a></section></li><li><section><a href="https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;mid=2247519765&amp;idx=1&amp;sn=ce5a8c8182f854c88043059f8c2cb9ff&amp;scene=21#wechat_redirect" data-linktype="2">千呼万唤始出来的独享生物信息学云服务器</a></section></li><li><section><a href="https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;mid=2247528144&amp;idx=1&amp;sn=be4d7e542d1077921024c86a4c130f16&amp;scene=21#wechat_redirect" data-linktype="2">永久免费的生信进阶培训（线下）</a></section></li></ul><p><br></p><p><br></p><p><mp-style-type data-value="10000"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/T9ITQwUrZpq4UyTQwMWeiA",target="_blank" rel="noopener noreferrer">原文链接</a>
