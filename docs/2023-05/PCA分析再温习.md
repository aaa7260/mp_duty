---
title: "PCA分析再温习"
date: 2023-05-11T15:08:19Z
draft: ["false"]
tags: [
  "fetched",
  "生信小知识"
]
categories: ["Acdemic"]
---
PCA分析再温习 by 生信小知识
------
<div><section><h2><span>PCA分析再温习</span></h2><blockquote><p>微信公众号：<strong>生信小知识</strong><br>关注可了解更多的生物信息学教程及知识。问题或建议，请公众号留言;</p></blockquote><h3><span>目录</span></h3><p><span><span>前言</span></span><span><span>1. PCA分析的一些术语及思想</span></span><span><span>2. R语言中2种PCA函数的差异</span></span><span><span><span>2.1 测试数据</span></span></span><span><span><span>2.2 princomp函数实战</span></span></span><span><span><span><span>2.2.1 输出结果数据理解</span></span></span></span><span><span><span>2.3 prcomp函数实战</span></span></span><span><span><span><span>2.3.1 输出结果数据理解</span></span></span></span><span><span><span>2.4 2个函数通用函数</span></span></span><span><span><span><span>2.4.1 get_eigenvalue/get_eig</span></span></span></span><span><span><span><span>2.4.2 get_pca_ind/get_pca_var</span></span></span></span><span><span><span><span>2.4.3 fviz_screeplot/fviz_eig</span></span></span></span><span><span><span><span>2.4.4 fviz_pca_ind/fviz_pca_var</span></span></span></span><span><span><span><span>2.4.5 fviz_pca_biplot</span></span></span></span><span><span>后记</span></span></p><h3><span>前言</span></h3><p>今天对PCA的原理简单回顾了下，就顺便把相关笔记进行简单分享。</p><p>先放上一些过去的笔记：</p><ul><li><p>关于原理部分，强烈建议看这个：<a href="https://mp.weixin.qq.com/s?__biz=MjM5NTk0Mzg2Nw==&amp;mid=2247484694&amp;idx=1&amp;sn=ccd9ffd78bd8d662de8bdd35397362d8&amp;scene=21#wechat_redirect" data-linktype="2">StatQuest - 主成分分析（PCA)</a></p></li><li><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5NTk0Mzg2Nw==&amp;mid=2247485689&amp;idx=1&amp;sn=fcae5c7a01c39ec1552eeb2fc712a8ca&amp;scene=21#wechat_redirect" data-linktype="2">R语言 PCA主成分分析</a></p></li><li><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5NTk0Mzg2Nw==&amp;mid=2247485695&amp;idx=1&amp;sn=d4cc8087fc23eb6331f449278054bb7a&amp;scene=21#wechat_redirect" data-linktype="2">R语言 PCA主成分分析（2）</a></p></li></ul><h3><span>1. PCA分析的一些术语及思想</span></h3><p>关于PCA中的几个术语解释：<strong>载荷分数 (Loading score)，特征值，奇异值</strong>。</p><p>参考下图来理解：</p><p><img data-galleryid="" data-ratio="0.6135416666666667" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRs36gYYOZ9xtpib4UorAfIOBJvETZn6tcSU69G67iaEWoibv4xvcZcXJrQ/640?wx_fmt=png" data-type="png" data-w="960" src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRs36gYYOZ9xtpib4UorAfIOBJvETZn6tcSU69G67iaEWoibv4xvcZcXJrQ/640?wx_fmt=png"></p><ul><li><p><strong>特征值（eigenvalue）</strong>：图中的SS（<strong>所有绿点的投影点x到原地距离的平方和</strong>）。</p></li><li><p><strong>奇异值（singular value）</strong>：特征值的<strong>平方根</strong>，看图也可以理解为是图中所有投影点x到原点的距离之和。</p></li></ul><blockquote><p>原点：x和y均值的坐标</p><p>根据上述定义，我们可以知道，如果将 <code>特征值/(样本量-1)</code> 即可得到方差。</p></blockquote><p><img data-galleryid="" data-ratio="0.6278240190249703" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRs3ibPdZUGTiaacWaPbzEp5afiav4hkOCibDAFdvGSJ1tJ40Wd87F1XLic5A/640?wx_fmt=png" data-type="png" data-w="841" src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRs3ibPdZUGTiaacWaPbzEp5afiav4hkOCibDAFdvGSJ1tJ40Wd87F1XLic5A/640?wx_fmt=png"></p><ul><li><p><strong>Loading</strong>：每个基因所占比例，越大说明贡献越多</p></li></ul><h3><span>2. R语言中2种PCA函数的差异</span></h3><p>reference：</p><ul><li><p><span>https://blog.csdn.net/weixin_44084325/article/details/90729121</span></p></li><li><p><span>https://blog.csdn.net/lfz_carlos/article/details/48442091</span></p></li></ul><p>总结来说：</p><table width="100"><thead><tr><th><br></th><th>princomp</th><th>prcomp</th></tr></thead><tbody><tr><td>算法</td><td><strong>协方差(covariance) 或者相关性矩阵提取的特征(eigen)</strong></td><td><strong>SVD分解</strong></td></tr><tr><td>载荷因子</td><td><strong>loadings</strong></td><td><strong>rotation</strong></td></tr><tr><td>计算协方差</td><td><strong>分母为N</strong></td><td><strong>分母为N-1</strong></td></tr><tr><td>推荐程度</td><td>**</td><td>***</td></tr></tbody></table><p>下面我们用一个测试数据，对这两个函数的用法和结果进行解析。</p><h4><span>2.1 测试数据</span></h4><pre><code><span># load the environment</span><br><span>if</span> (<span>T</span>) {<br>  rm(list = ls())<br>  options(stringAsFactors = <span>F</span>)<br>  <span>library</span>(stringr)<br>  <span>library</span>(ggplot2)<br>  <span>library</span>(reshape2)<br>}<br><br><span># prepare for test data</span><br><span>if</span> (<span>T</span>) {<br>  test&lt;-data.frame(<br>    X1=c(<span>148</span>, <span>139</span>, <span>160</span>, <span>149</span>, <span>159</span>, <span>142</span>, <span>153</span>, <span>150</span>, <span>151</span>, <span>139</span>,<br>         <span>140</span>, <span>161</span>, <span>158</span>, <span>140</span>, <span>137</span>, <span>152</span>, <span>149</span>, <span>145</span>, <span>160</span>, <span>156</span>,<br>         <span>151</span>, <span>147</span>, <span>157</span>, <span>147</span>, <span>157</span>, <span>151</span>, <span>144</span>, <span>141</span>, <span>139</span>, <span>148</span>),<br>    X2=c(<span>41</span>, <span>34</span>, <span>49</span>, <span>36</span>, <span>45</span>, <span>31</span>, <span>43</span>, <span>43</span>, <span>42</span>, <span>31</span>,<br>         <span>29</span>, <span>47</span>, <span>49</span>, <span>33</span>, <span>31</span>, <span>35</span>, <span>47</span>, <span>35</span>, <span>47</span>, <span>44</span>,<br>         <span>42</span>, <span>38</span>, <span>39</span>, <span>30</span>, <span>48</span>, <span>36</span>, <span>36</span>, <span>30</span>, <span>32</span>, <span>38</span>),<br>    X3=c(<span>72</span>, <span>71</span>, <span>77</span>, <span>67</span>, <span>80</span>, <span>66</span>, <span>76</span>, <span>77</span>, <span>77</span>, <span>68</span>,<br>         <span>64</span>, <span>78</span>, <span>78</span>, <span>67</span>, <span>66</span>, <span>73</span>, <span>82</span>, <span>70</span>, <span>74</span>, <span>78</span>,<br>         <span>73</span>, <span>73</span>, <span>68</span>, <span>65</span>, <span>80</span>, <span>74</span>, <span>68</span>, <span>67</span>, <span>68</span>, <span>70</span>),<br>    X4=c(<span>78</span>, <span>76</span>, <span>86</span>, <span>79</span>, <span>86</span>, <span>76</span>, <span>83</span>, <span>79</span>, <span>80</span>, <span>74</span>,<br>         <span>74</span>, <span>84</span>, <span>83</span>, <span>77</span>, <span>73</span>, <span>79</span>, <span>79</span>, <span>77</span>, <span>87</span>, <span>85</span>,<br>         <span>82</span>, <span>78</span>, <span>80</span>, <span>75</span>, <span>88</span>, <span>80</span>, <span>76</span>, <span>76</span>, <span>73</span>, <span>78</span>)<br>  )<br>  rownames(test) &lt;- paste0(<span>"student_"</span>,<span>1</span>:<span>30</span>)<br>  colnames(test) &lt;- c(<span>"height"</span>,<span>"weight"</span>,<span>"chest"</span>,<span>"sit-h"</span>)<br>}<br><br>head(test)<br><span>##           height weight chest sit-h</span><br><span>## student_1    148     41    72    78</span><br><span>## student_2    139     34    71    76</span><br><span>## student_3    160     49    77    86</span><br><span>## student_4    149     36    67    79</span><br><span>## student_5    159     45    80    86</span><br><span>## student_6    142     31    66    76</span><br></code></pre><p>注意：<strong>input数据row是样本，column是变量</strong></p><h4><span>2.2 princomp函数实战</span></h4><pre><code><span># princomp</span><br>test.pr &lt;- princomp(test, cor=<span>TRUE</span>)<br>summary(test.pr, loadings=<span>TRUE</span>)<br><span>## Importance of components:</span><br><span>##                           Comp.1     Comp.2     Comp.3     Comp.4</span><br><span>## Standard deviation     1.8817805 0.55980636 0.28179594 0.25711844</span><br><span>## Proportion of Variance 0.8852745 0.07834579 0.01985224 0.01652747</span><br><span>## Cumulative Proportion  0.8852745 0.96362029 0.98347253 1.00000000</span><br><span>## </span><br><span>## Loadings:</span><br><span>##        Comp.1 Comp.2 Comp.3 Comp.4</span><br><span>## height  0.497  0.543  0.450  0.506</span><br><span>## weight  0.515 -0.210  0.462 -0.691</span><br><span>## chest   0.481 -0.725 -0.175  0.461</span><br><span>## sit-h   0.507  0.368 -0.744 -0.232</span><br></code></pre><p>我们可以看到在 <code>summary</code> 函数的作用下，输出的结果有2部分，其中上面部分一共有3行：</p><ul><li><p><span>第1行（Standard deviation）：每个PC的标准差</span></p></li><li><p>第2行（Proportion of Variance）：每个PC<strong>所能解释数据方差的比例</strong>，该值可以通过将第1行数据取平方后，计算每个数值所占比例得到。</p></li><li><p>第3行（Proportion of Variance）：所有PC<strong>累积</strong>解释数据方差的比例。</p></li></ul><p>下面部分则是每个PC的Loadings，根据这个数据，我们可以知道每个PC的计算公式：</p><ul><li><p><code>PC1 = 0.497 x height + 0.515 x weight + 0.481 x chest + 0.507 x sit-h</code></p></li><li><p><code>PC2 = 0.543 x height - 0.210 x weight - 0.725 x chest + 0.368 x sit-h</code></p></li><li><p><code>PC3 = 0.450 x height + 0.462 x weight - 0.175 x chest - 0.744 x sit-h</code></p></li><li><p><code>PC4 = 0.506 x height - 0.691 x weight + 0.461 x chest - 0.232 x sit-h</code></p></li></ul><h5><span>2.2.1 输出结果数据理解</span></h5><p>我们可以看看 <code>test.pr</code> 的数据结构：</p><p><img data-galleryid="" data-ratio="0.598605577689243" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRMzv1ibFDFay9jQvM9X8M3picbV2z8oKR2MibiavErqHiaQOVIpc4AcNQ4MA/640?wx_fmt=png" data-type="png" data-w="1004" src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRMzv1ibFDFay9jQvM9X8M3picbV2z8oKR2MibiavErqHiaQOVIpc4AcNQ4MA/640?wx_fmt=png"></p><p>这里的数据含义如下：</p><ul><li><p><code>sdev</code>：每个PC的标准差</p></li><li><p><code>loadings</code>：每个PC中不同变量的比例，<strong>根据该值，我们可以得到每个PC的计算公式</strong></p></li><li><p><code>center</code>：每个变量的<strong>均值</strong>（mean）</p></li><li><p><code>scale</code>：所有数据进行scale时缩放因子，<strong>原始数据除以该值</strong></p></li><li><p><code>n.obs</code>：有多少样本数，即input数据的行数</p></li><li><p><code>scores</code>：每个样本的PC值，<strong>我们在绘制PCA图时即使用这里的数据进行绘制</strong></p></li></ul><blockquote><p>当 <code>cor=F</code> 时，<code>princomp</code> 函数会<strong>假设变量间的协方差和方差的度量单位相同</strong>，不考虑它们之间的标度变化；</p><p>当 <code>cor=T</code> 时， <code>princomp</code> 函数则会先将数据<strong>按照列zscale标准化</strong>（也就是将每列的平均值变成0，方差变成1），然后基于标准化后的数据计算原始数据的主成分，这样各个变量的度量单位并不会影响到主成分的计算结果。</p></blockquote><p>而对于PCA绘图所用到的数据，存放在 <code>test.pr$scores</code>：</p><pre><code>head(test.pr$scores)<br><span>##               Comp.1      Comp.2      Comp.3      Comp.4</span><br><span>## student_1 -0.0699095 -0.23813701  0.35509248 -0.26612014</span><br><span>## student_2 -1.5952634 -0.71847399 -0.32813232 -0.11805665</span><br><span>## student_3  2.8479315  0.38956679  0.09731731 -0.27948249</span><br><span>## student_4 -0.7599699  0.80604335  0.04945722 -0.16294930</span><br><span>## student_5  2.7396678  0.01718087 -0.36012615  0.35865304</span><br><span>## student_6 -2.1058317  0.32284393 -0.18600422 -0.03645608</span><br><br><span>library</span>(factoextra)<br><span># PCA结果图</span><br>fviz_pca_ind(test.pr)<br><span># 手动画散点图</span><br>ggplot(as.data.frame(test.pr$scores),aes(Comp.1,Comp.2)) + geom_point()<br></code></pre><p>PCA结果图：</p><p><img data-galleryid="" data-ratio="0.6877593360995851" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuR0lXXucTCud45tbwFfQ6HbhZeA4K4kxr1kMRL4LSiaWAGjfabeZSQzCQ/640?wx_fmt=png" data-type="png" data-w="964" src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuR0lXXucTCud45tbwFfQ6HbhZeA4K4kxr1kMRL4LSiaWAGjfabeZSQzCQ/640?wx_fmt=png"></p><p>手动画散点图：</p><p><img data-galleryid="" data-ratio="0.6877593360995851" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuREKUMJG15fibtkdlasshmngZJCrxAogbAcvk0EIEn7Q4IdFHGjwRiaCZA/640?wx_fmt=png" data-type="png" data-w="964" src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuREKUMJG15fibtkdlasshmngZJCrxAogbAcvk0EIEn7Q4IdFHGjwRiaCZA/640?wx_fmt=png"></p><p>可以看到，这两者的结果图是一样的</p><h4><span>2.3 prcomp函数实战</span></h4><pre><code><span># prcomp</span><br>test.pr &lt;- prcomp(test, retx=<span>T</span>, center = <span>T</span>, scale.=<span>T</span>)<br>test.pr<br><span>## Standard deviations (1, .., p=4):</span><br><span>## [1] 1.8817805 0.5598064 0.2817959 0.2571184</span><br><span>## </span><br><span>## Rotation (n x k) = (4 x 4):</span><br><span>##              PC1        PC2        PC3        PC4</span><br><span>## height 0.4969661 -0.5432128  0.4496271  0.5057471</span><br><span>## weight 0.5145705  0.2102455  0.4623300 -0.6908436</span><br><span>## chest  0.4809007  0.7246214 -0.1751765  0.4614884</span><br><span>## sit-h  0.5069285 -0.3682941 -0.7439083 -0.2323433</span><br><br>summary(test.pr)<br><span>## Importance of components:</span><br><span>##                           PC1     PC2     PC3     PC4</span><br><span>## Standard deviation     1.8818 0.55981 0.28180 0.25712</span><br><span>## Proportion of Variance 0.8853 0.07835 0.01985 0.01653</span><br><span>## Cumulative Proportion  0.8853 0.96362 0.98347 1.00000</span><br></code></pre><blockquote><p>对于 <code>prcomp</code> 函数中几个重要的参数：</p><ul><li><p><code>retx</code>：是否返回 <code>Rotation</code> 数据，默认为T</p></li><li><p><code>center</code>：是否将数据中心化，默认为T，这里建议使用T，原因可以参考很早之前我写过的介绍PCA原理的推文 【<a href="https://mp.weixin.qq.com/s?__biz=MjM5NTk0Mzg2Nw==&amp;mid=2247484694&amp;idx=1&amp;sn=ccd9ffd78bd8d662de8bdd35397362d8&amp;scene=21#wechat_redirect" data-linktype="2">StatQuest - 主成分分析（PCA)</a>】</p></li><li><p><code>scale.</code>：是否将数据进行缩放，以保证所有数据的量纲相同，默认为F，但是<strong>建议使用T</strong></p></li></ul></blockquote><p>其实可以看到，两个函数的结果其实都是一样的，只是在 <code>princomp</code> 函数中的 <code>loadings</code> 结果，在 <code>prcomp</code> 函数中存放在了 <code>Rotation</code> 中。</p><h5><span>2.3.1 输出结果数据理解</span></h5><p>同样，我们还是可以看看 <code>test.pr</code> 的数据结构：</p><p><img data-galleryid="" data-ratio="0.4308779011099899" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRAJA5rQIGrsyGzUvnlnTyhTicEwu3Gxvo4P8FIwAa5V2d6ze0vrUics1w/640?wx_fmt=png" data-type="png" data-w="991" src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRAJA5rQIGrsyGzUvnlnTyhTicEwu3Gxvo4P8FIwAa5V2d6ze0vrUics1w/640?wx_fmt=png"></p><p>这里的数据含义如下：</p><ul><li><p><code>sdev</code>：每个PC的标准差</p></li><li><p><code>rotation</code>：每个PC中不同变量的比例，<strong>根据该值，我们可以得到每个PC的计算公式</strong></p></li><li><p><code>center</code>：每个变量的<strong>均值</strong>（mean）</p></li><li><p><code>scale</code>：所有数据进行scale时缩放因子，<strong>原始数据除以该值</strong>。这里的结果与 <code>princomp</code> 函数稍稍不同，是因为他们在计算协方差时有一点点差异。不过影响不大。</p></li><li><p><code>x</code>：每个样本的PC值，<strong>我们在绘制PCA图时即使用这里的数据进行绘制</strong></p></li></ul><p>对于PCA绘图所用到的数据，存放在 <code>test.pr$x</code>：</p><pre><code>head(test.pr$x)<br><span>##                   PC1        PC2         PC3         PC4</span><br><span>## student_1 -0.06873446  0.2341344  0.34912411 -0.26164721</span><br><span>## student_2 -1.56845034  0.7063979 -0.32261710 -0.11607236</span><br><span>## student_3  2.80006371 -0.3830190  0.09568161 -0.27478497</span><br><span>## student_4 -0.74719637 -0.7924954  0.04862595 -0.16021046</span><br><span>## student_5  2.69361965 -0.0168921 -0.35407318  0.35262483</span><br><span>## student_6 -2.07043703 -0.3174176 -0.18287788 -0.03584333</span><br></code></pre><h4><span>2.4 2个函数通用函数</span></h4><p>无论是使用 <code>prcomp</code> 函数还是 <code>princomp</code> 函数，对于得到的结果，我们都可以使用下面的几个函数进行后续数据提取：</p><ul><li><p><code>get_eigenvalue(test.pr) / get_eig(test.pr)</code></p></li><li><p><code>get_pca_ind(test.pr)</code></p></li><li><p><code>$coord</code></p></li><li><p><code>$contrib</code></p></li><li><p><code>get_pca_var(test.pr)</code></p></li><li><p><code>$coord</code></p></li><li><p><code>$contrib</code></p></li></ul><p>可视化展示：</p><ul><li><p><code>fviz_screeplot(test.pr) / fviz_eig(test.pr)</code></p></li><li><p><code>fviz_pca_ind(test.pr)</code></p></li><li><p><code>fviz_pca_var(test.pr)</code></p></li><li><p><code>fviz_pca_biplot(test.pr)</code></p></li></ul><h5><span>2.4.1 get_eigenvalue/get_eig</span></h5><blockquote><p><code>get_eig</code> 是 <code>get_eigenvalue</code> 函数的简写</p></blockquote><p>该函数可以提取特征值，在前面提到过，所谓特征值，其实和PC可以解释数据的方差联系十分紧密，因此在该函数中，其实得到的结果就是：<strong>每个PC可以解释数据的方差</strong>：</p><pre><code>get_eigenvalue(test.pr)<br><span>##       eigenvalue variance.percent cumulative.variance.percent</span><br><span>## Dim.1 3.54109800        88.527450                    88.52745</span><br><span>## Dim.2 0.31338316         7.834579                    96.36203</span><br><span>## Dim.3 0.07940895         1.985224                    98.34725</span><br><span>## Dim.4 0.06610989         1.652747                   100.00000</span><br></code></pre><p>行名：每个PC</p><p>列名：</p><ul><li><p><code>eigenvalue</code>：每个PC可以解释的数据方差大小</p></li><li><p><code>variance.percent</code>：计算每个PC可以解释的数据方差占总方差的比例</p></li><li><p><code>cumulative.variance.percent</code>：累计可以解释数据方差的比例</p></li></ul><h5><span>2.4.2 get_pca_ind/get_pca_var</span></h5><p>这两个函数是分别针对样本和变量进行提取数据的：</p><ul><li><p><code>get_pca_ind</code>：individual，针对样本</p></li><li><p><code>get_pca_var</code>：variable，针对变量</p></li></ul><p>这两个函数不能直接返回有效数据，后面需要接上我们想要的数据类型。一般多接：</p><ul><li><p><code>$coord</code>：返回在PCA中每个样本/变量的PC坐标</p></li><li><p><code>$contrib</code>：返回在PCA中每个样本/变量的loading/rotation在每个PC中所占比例（<strong>注意：不是loading/rotation的具体值</strong>）</p></li></ul><p>例如：</p><pre><code><span># 对于每个PC而言，不同变量的贡献度</span><br>get_pca_var(test.pr)$contrib<br><span>##           Dim.1     Dim.2     Dim.3     Dim.4</span><br><span>## height 24.69753 29.508014 20.216452 25.578009</span><br><span>## weight 26.47828  4.420317 21.374905 47.726494</span><br><span>## chest  23.12655 52.507618  3.068681 21.297156</span><br><span>## sit-h  25.69765 13.564052 55.339962  5.398341</span><br><br><span># 对于每个样本而言，在PCA中的PC坐标</span><br>head(get_pca_ind(test.pr)$coord)<br><span>##                 Dim.1      Dim.2       Dim.3       Dim.4</span><br><span>## student_1 -0.06873446  0.2341344  0.34912411 -0.26164721</span><br><span>## student_2 -1.56845034  0.7063979 -0.32261710 -0.11607236</span><br><span>## student_3  2.80006371 -0.3830190  0.09568161 -0.27478497</span><br><span>## student_4 -0.74719637 -0.7924954  0.04862595 -0.16021046</span><br><span>## student_5  2.69361965 -0.0168921 -0.35407318  0.35262483</span><br><span>## student_6 -2.07043703 -0.3174176 -0.18287788 -0.03584333</span><br></code></pre><h5><span>2.4.3 fviz_screeplot/fviz_eig</span></h5><blockquote><p><code>fviz_eig</code> 是 <code>fviz_screeplot</code> 函数的简写</p></blockquote><p>使用该函数，可以绘制出碎石图，根据碎石图可以帮助我们判断PC数目的选择：</p><pre><code>fviz_eig(test.pr)<br></code></pre><p><img data-galleryid="" data-ratio="0.6877593360995851" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRA33Zy6WCopVOH4bicuHyuZzF1gX2aloOFXic3qBm0XcGBMklIaMpZLQw/640?wx_fmt=png" data-type="png" data-w="964" src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRA33Zy6WCopVOH4bicuHyuZzF1gX2aloOFXic3qBm0XcGBMklIaMpZLQw/640?wx_fmt=png"></p><p>可以看到，前2个PC已经解释了数据的绝大多数方差了。</p><p>当然，我们也可以使用自带的另外一个函数进行绘制碎石图：</p><pre><code>screeplot(test.pr,type=<span>"lines"</span>)<br></code></pre><p><img data-galleryid="" data-ratio="0.5746887966804979" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRheLITfrulKmNxp81ic5PdRCplD5CJcJUpPFenuX7cURWYMwBzAIGMNg/640?wx_fmt=png" data-type="png" data-w="964" src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRheLITfrulKmNxp81ic5PdRCplD5CJcJUpPFenuX7cURWYMwBzAIGMNg/640?wx_fmt=png"></p><h5><span>2.4.4 fviz_pca_ind/fviz_pca_var</span></h5><p>这两个函数是分别针对样本和变量进行可视化PCA图：</p><ul><li><p><code>fviz_pca_ind</code>：individual，针对样本</p></li><li><p><code>fviz_pca_var</code>：variable，针对变量</p></li></ul><pre><code>fviz_pca_ind(test.pr)<br></code></pre><p><img data-galleryid="" data-ratio="0.6877593360995851" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRoebqaa2WAydXfibibuyLF4Objuolyic2tD9NOdibdicI3wxQyKFibicHc9jzw/640?wx_fmt=png" data-type="png" data-w="964" src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRoebqaa2WAydXfibibuyLF4Objuolyic2tD9NOdibdicI3wxQyKFibicHc9jzw/640?wx_fmt=png"></p><pre><code>fviz_pca_var(test.pr)<br></code></pre><p><img data-galleryid="" data-ratio="0.6877593360995851" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRMA2hfBt3hOvoevA0XiaOtbVxxzy5MNfRtbfbj0rrHxDJOTkCPUGzcgw/640?wx_fmt=png" data-type="png" data-w="964" src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRMA2hfBt3hOvoevA0XiaOtbVxxzy5MNfRtbfbj0rrHxDJOTkCPUGzcgw/640?wx_fmt=png"></p><blockquote><p>这个结果可以告诉我们，每个变量对于定义PC1和PC2的重要性</p></blockquote><h5><span>2.4.5 fviz_pca_biplot</span></h5><p>这个函数则是将 <code>fviz_pca_ind</code> 和 <code>fviz_pca_var</code> 的结果合并起来，绘制在一张图上进行展示：</p><pre><code>fviz_pca_biplot(test.pr)<br></code></pre><p><img data-galleryid="" data-ratio="0.6877593360995851" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRrArvqzDEnzaXdOPEljISDlr35zROfm7XpAjP8UdDHksj27Z34pbp7Q/640?wx_fmt=png" data-type="png" data-w="964" src="https://mmbiz.qpic.cn/mmbiz_png/fOo3cmIWvJreRicGP19mBdbzXXxNaSmuRrArvqzDEnzaXdOPEljISDlr35zROfm7XpAjP8UdDHksj27Z34pbp7Q/640?wx_fmt=png"></p><h3><span>后记</span></h3><p>后续有需求再做补充~</p></section><p><br></p><p><mp-style-type data-value="3"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/cyJZ2xOKkDZD-dAeqGTG9w",target="_blank" rel="noopener noreferrer">原文链接</a>
