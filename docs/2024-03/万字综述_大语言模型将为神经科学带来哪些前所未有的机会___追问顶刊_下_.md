---
title: "万字综述：大语言模型将为神经科学带来哪些前所未有的机会？| 追问顶刊（下）"
date: 2024-03-19T09:01:47Z
draft: ["false"]
tags: [
  "fetched",
  "追问nextquestion"
]
categories: ["Acdemic"]
---
万字综述：大语言模型将为神经科学带来哪些前所未有的机会？| 追问顶刊（下） by 追问nextquestion
------
<div><section><section powered-by="xiumi.us"><section><img data-ratio="1.25" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHEh45zLuibLuEFmG7O3VlKUsz90L1lQd9R0NFzLflMdwOuNzqg4GBib8g/640?wx_fmt=png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHEh45zLuibLuEFmG7O3VlKUsz90L1lQd9R0NFzLflMdwOuNzqg4GBib8g/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p><br></p></section><section powered-by="xiumi.us"><p>大语言模型（LLMs）是机器学习领域中用于处理和生成自然语言文本的新工具。该文提供了对该建模技术的属性定义，并反思LLMs如何被用来重新构建经典的神经科学问题，以提供新的答案。</p><p><br></p><p>我们认为LLMs有潜力（1）通过添加如高级文本情感分析等有价值的元信息来丰富神经科学数据集；（2）总结大量信息来源，以克服孤立的神经科学社群之间的隔阂；（3）促使与大脑相关的不同信息源得以进行前所未有的融合；（4）帮助确定哪些认知概念能最有效地把握大脑中的现象。</p><p><br></p><p>本文为论文下篇，书接上文LLMs的属性及能力等背景介绍，重点讨论LLMs在解决神经科学与生物医学问题方面的运用。</p></section><section powered-by="xiumi.us"><section><img data-ratio="0.6712962962962963" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHnWQP8NIibZkibwoOo9LLOwLzzhPrA2eZxhtKVnaypUtqcV1YbpQibDYEg/640?wx_fmt=png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHnWQP8NIibZkibwoOo9LLOwLzzhPrA2eZxhtKVnaypUtqcV1YbpQibDYEg/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p>上篇：</p><p><a href="https://mp.weixin.qq.com/s?__biz=MzI3MjQ4MDMyOQ==&amp;mid=2247510862&amp;idx=1&amp;sn=f98adf09c453cd6e509a8433a90b3821&amp;scene=21#wechat_redirect" target="_blank" data-linktype="2">万字综述：写给神经科学家的大语言模型基础原理 | 追问顶刊（上）</a></p></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><section><section><img data-ratio="0.4638888888888889" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66ia7QDJLgwvG7n6VBU0kwiaOzq2HvpTA8w9tBOVD6ibReucoibUETQgq73aXkesXKCb3pFrWeH18OBYlA/640?wx_fmt=png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66ia7QDJLgwvG7n6VBU0kwiaOzq2HvpTA8w9tBOVD6ibReucoibUETQgq73aXkesXKCb3pFrWeH18OBYlA/640?wx_fmt=png"></section></section></section><section powered-by="xiumi.us"><section><p><strong>▷ </strong><span><span>Bzdok, Danilo, et al. "Data science opportunities of large language models for neuroscience and biomedicine." Neuron (2024). https://doi.org/10.1016/j.neuron.2024.01.016</span></span></p></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><section><img data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hOuC4CDbz41JswsKHVHPGNYWHGvEdb5ZCnhdQkfjjaBoUdiaic6D1NHQPSfyS7SnlXCJGic7okkiarbw/640?wx_fmt=png" data-ratio="0.5631399317406144" data-w="293" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hOuC4CDbz41JswsKHVHPGNYWHGvEdb5ZCnhdQkfjjaBoUdiaic6D1NHQPSfyS7SnlXCJGic7okkiarbw/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><section><p><strong>大型语言模型在生物序列中的应用</strong><br></p></section></section><section powered-by="xiumi.us"><p><br></p></section><section powered-by="xiumi.us"><p>LLM学习引擎的归纳能力，不仅适用于词序列，也同样适用于各种类型的生物序列，这提供了许多未被充分挖掘的研究机会。人类的基因组，这一包含约2万个基因的庞大DNA序列库，构成了大脑及身体其他部位细胞内蛋白质合成的基石。在此基础上，<strong><span>“生物学中心法则”为我们提供了一个与神经科学直接相关的自然试验场景</span></strong>，它描述了遗传信息如何从DNA中的核苷酸序列，通过信使RNA中的碱基序列，最终转化为蛋白质产品中的氨基酸序列的流动过程。<br></p><p><br></p><p>遗传学家的主要目标是映射这种遗传信息的传递过程，将DNA序列本身的改变与相应的功能影响联系起来。为此，MetaAI展示了一种蛋白质语言模型（图3），该模型能从遗传变异的差异中预测表型后果<sup>[29]</sup>。通过一个拥有6.5亿参数的模型，研究者能够推断人类基因组中大约4.5亿种可能的错义变异效应——每种变异都是DNA中单个核苷酸的替换，这一替换可能导致下游蛋白质中的氨基酸交换（有害或良性）。DNA基因编码中的这些变异特别有趣，因为它们涉及可以与疾病机制和可能的治疗目标联系起来的蛋白质改变。这种方法使我们能全面分析人类和其他生物整个基因组中的蛋白质破坏性损伤变异。</p><p><br></p></section><section powered-by="xiumi.us"><section><section><img data-ratio="0.7884362680683311" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHMMT7BzBA2HfGhicMjvQyiaOvbhPSjRFAUo7ZaOFHndgvPvo7k5FRQtdw/640?wx_fmt=png" data-w="761" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHMMT7BzBA2HfGhicMjvQyiaOvbhPSjRFAUo7ZaOFHndgvPvo7k5FRQtdw/640?wx_fmt=png"></section></section></section><section powered-by="xiumi.us"><section><p><strong>▷ </strong><span><span>图3，蛋白语言模型可预测基因突变的功能影响</span></span></p></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>此外，我们能否仅从RNA转录表达数据中自动推导出细胞状态和与活跃生物通路相关的洞见？在单细胞RNA基因表达水平上，一个LLM<sup>[30]</sup>在1000万个细胞上进行了训练（图4），每个细胞包含大约2万个人类基因的一部分表达值。作为一个基础模型的开创性例子（参见上文），基因集在生物学建模中构成有意义的过程，类似于词语集合在语言中构成有意义的句子。通过吸收大量的基因表达模式，该模型形成了基因间关系和基因-细胞关系的普遍性内部表征。除了特定基因的标记外，模型还引入了特殊的标记来表示元信息，如细胞类型、数据批次以及实验条件，如信号通路的扰动和RNA转录测序使用的技术。</p><p><br></p><p>作者还取消了输入必须是序列的需求——他们设计了一个任务定制的注意力机制，以紧密把握表达基因的协同出现模式。通过基于迭代预测集合中新基因表达的自回归生成，类似于在连续的句子中预测下一个词汇。也就是说，<span><strong>他们将传统语言模型处理词序的方式，巧妙转化为在单细胞基础模型中处理细胞对应的基因集合，从而摆脱了输入必须遵循序列的限制</strong></span>。</p><p><br></p><p>这样一来，模型一旦建立，训练好的基础LLM就可以进行微调和部署，并在各种不同的下游任务中获得性能提升，包括批次校正、细胞类型注释和目标扰动条件的预测。<span><strong>这种方法不仅展现了自监督学习技术掌握复杂单细胞机制的潜能，还能利用后续的内部嵌入表示，实现不同器官和物种间的数据整合。</strong></span></p></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><section><section><img data-ratio="0.775" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHcXXPibeSeo2gygNfO3BQqISm6LGFiad0MKCeL5GpYkpKHcNkoWwC4Uow/640?wx_fmt=png" data-w="760" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHcXXPibeSeo2gygNfO3BQqISm6LGFiad0MKCeL5GpYkpKHcNkoWwC4Uow/640?wx_fmt=png"></section></section></section><section powered-by="xiumi.us"><section><p><strong>▷ </strong><span><span>图4，从指数级增加的单细胞转录组数据中，构建基础模型以描述细胞转录的语法</span></span></p></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>从基因层面到3D蛋白质结构层面的转变，关键在于能否仅凭一维氨基酸序列预测出蛋白质的最终三维构型。蛋白质折叠问题围绕着我们的DNA是如何压缩关于最终蛋白质结构信息的。在数据库中有超过2亿种蛋白质结构，AlphaFold<sup>[31]</sup>这一基于大型语言模型的系统，通过捕捉沿着蛋白质骨架上远离彼此的氨基酸残基之间的序列相互作用。在这个给使用暴力（brute force）学习的研究中，研究者展示了1D序列信息确实包含了理解蛋白质在自然界中实际折叠的复杂过程所需的关键信息。</p><p><br></p><p>在蛋白质到功能层面，研究者在250亿个蛋白质序列（UniParc数据库）的860亿个氨基酸上训练了7亿参数的34层transformer模型<sup>[32]</sup>。模型内部的嵌入表征仅从序列信息本身获得。<strong><span>训练好的模型被发现能够包含蛋白质的生化特性、体内形态结构元素、接触位点和生物活性相关知识。</span></strong></p><p><br></p><p>总的来说，捕捉长距离相互作用（即输入序列中相距较远的标记）不仅在词序列推理中，也在不同生物序列中有意义的一般原则方面显得非常有价值。<span><strong>自然界似乎隐藏着可以被利用来推断超出实际序列元素</strong></span>（例如，核酸、基因表达、氨基酸）<span><strong>的潜在一般规则，以服务于下一代计算生物学。</strong></span>学到的序列嵌入可以用于各种下游研究目标，包括质量控制程序、生物实体的分组以及增强表型预测。</p><p><br></p><p>此外，LLMs作为一个平台现已能够实现生物学中心法则的先进计算模拟，从DNA的双螺旋结构到基因的转录表达，再到完整的蛋白质形态。也就是说，<span><strong>一旦LLM能够准确地近似目标系统，便能通过复现严格实验中的可靠观察，使研究者得以向询问LLM询问，以提取关于目标系统的新分子洞察，并识别更广泛的驱动生物机制</strong></span>。我们警告不要将基于LLM的功能预测模型和分子生物学系统之间视为严格平行，因为两者存在显著差异。尽管如此，在未来，LLMs仍将占据独特的位置，有望帮助发现从未在自然界中观察到的生物活性序列。</p></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><section><img data-ratio="0.43902439024390244" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hOuC4CDbz41JswsKHVHPGNnfGricJMoAfFdDqKlHhyLuQUhVdSicGq0r14lTCGTcZEQyqicdDx9lY6w/640?wx_fmt=png" data-w="369" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hOuC4CDbz41JswsKHVHPGNnfGricJMoAfFdDqKlHhyLuQUhVdSicGq0r14lTCGTcZEQyqicdDx9lY6w/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><section><p><strong>用于自动化数据标注的大模型</strong><br></p></section></section><section powered-by="xiumi.us"><p><br></p></section><section powered-by="xiumi.us"><p>神经科学研究经常依赖于准确的数据标注来阐述数据、设计实验或解释结果。</p><p><br></p><p><strong><span>（1）文字标注</span></strong></p><p><br></p><p>最近一项使用传统NLP的研究探讨了观看电影《阿甘正传》的受试者的大脑反应信号与电影故事的发展之间的关系，即电影叙事的语义元素如何与大脑活动相联系<sup>[33]</sup>。这项研究是依赖于数据点相关高质量标注研究的典范。这项研究利用了来自studyforrest*数据库收集的大脑记录，每个受试者在观看2小时电影的过程中，其全脑神经活动的3000张个体图像被详细捕获。<br></p><p><br></p></section><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><p><span>*https://www.studyforrest.org/data.html</span><br></p></section></section></section></section><section powered-by="xiumi.us"><p><br></p><p>为了使该数据集更丰富，电影中的每一个场景都通过计算生成的元信息得到增强。为此，文本数据来自之前未充分利用的来源：即与视频内容同步显示的时间锁定字幕，和面向盲人的仅听觉叙述版本的电影，后者描述了电影中的事件和场景，展现了NLP支持下的数据增强的初步尝试。</p></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><section><section><img data-ratio="0.7707509881422925" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHaR4lEkFqJCsibrOeBcEXica1YdyuXLdsK0LWql8ttbJuHrucicaJqGa2A/640?wx_fmt=png" data-w="759" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHaR4lEkFqJCsibrOeBcEXica1YdyuXLdsK0LWql8ttbJuHrucicaJqGa2A/640?wx_fmt=png"></section></section></section><section powered-by="xiumi.us"><section><p><span><strong>▷</strong></span><strong> </strong><span>图5：基于电影文本，使用NLP进行多模态脑-文字数据整合</span></p></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>《阿甘正传》的逐场景文本信息被一个词袋模型（bag-of-words）所捕捉——在电影整个播放过程中，该模型会收集每个时间片段内所有独特词汇及其出现频率的集合。然后使用潜在语义分析来将场景词频分解为独特的语义维度，以捕捉故事线中的潜在意义和反复出现的主题。</p><p><br></p><p>与此同时，通过一种经典的自上而下方法，人类标注者（一群学生）通过从电影的视听版本中选择52个预定义的“指标”来手动为场景添加标签。这些选择基于场景的情感内容、情境和其他方面，基于现有知识，这些方面预先被认为与电影场景相关。<span><strong>这种经典方法虽然强调了基于人类观察者的自然主观体验对人类情感的详细刻画，然而事实上却错过了基于文本派生语义表征中，被很好地反映了的重要细节。</strong></span>这一自动标准的成功，展示了未来LLM方法在自然神经科学中的潜力。</p><p><br></p><p>超越手动标注的局限，NLP方法（如潜在语义分析）使得故事被分解为200个语义上下文单元，每个单元基于上下文都与特定场景紧密相关。作为人类衍生情感标注的补充，语义上下文提供了追踪角色（例如，丹中尉）、情境（例如，战争）和场景属性（例如，白天与夜晚）的方法。通过整合数据分析，揭示了大脑状态与场景中特定元素、概念和主题之间的经验联系。因此，算法派生的语义方面在电影-大脑-文本分析中，相较于传统依赖人类先验直觉确定的那些最重要的方向，展现出了更为显著的成功。</p><p><br></p><p>LLMs为将其他学科对人类行为的知识和概念引入到脑科学研究中提供了前所未有的机会。批量标注生成可以极大地增强我们处理复杂操作协议的能力，如上述研究中使用的图像和视频数据，以及许多其他形式的数据，如电子健康记录、语音记录或可穿戴设备捕获的生物测量。</p><p><br></p><p>历史上，这些数据形式的标注需要人类专家的输入，无论是直接还是间接。现在，通过专门针对特定的从输入到输出的端到端工具，例如直接从视觉数据中训练神经网络来识别人类情感，或基于物理特性预测气味化合物吸引力的电子嗅觉设备<sup>[34]</sup>，我们可以更高效地完成这些任务。<strong><span>手动标注通常存在一些问题，LLMs可以缓解其中几个问题，包括（1）手动操作的高物流和财务成本，（2）用于派生标注标签的分类系统的本体论限制，（3）人类标注者的主观性以及基于主观性的数据，以及（4）可重复性。</span></strong></p><p><br></p><p>最终，如上所述，由于成本高，手动标注的视觉和语言数据集相对罕见且规模较小（10,000-100,000个数据点）。为了应对先前的标注数据稀缺，许多研究<sup>[35-37]</sup>已经开始自动从互联网和其他通用来源抓取现成的配对视觉-文本数据。现在，以在文本-文本标注场景中也实现与图像-文本标注领域取得的类似成就。在模型预训练后，LLMs可以自动生成标注，这些预训练是基于与手头标注任务相关的各种数据完成。</p><p><br></p><p>举一个例子，一家生物技术公司有兴趣为描述精神活性药物体验的一手描述打上标签，以指示不同的主观效果；这些描述和手动标注的主观效果标签配对，可以用于公司使用的基线模型的微调。或者，像GPT4这样的LLMs可以在没有任何额外训练数据的情况下执行此任务，基于其训练集提供了足够的上下文来区分描述不同的主观效果术语及其示例。</p><p><br></p><p>短语和句子，就像单个单词一样，可以被自动赋予信息丰富的语义嵌入，这一过程同样适用于自动（或手动）获得的标注。通过将自然语言经LLM“编码器”预处理为嵌入向量，我们可以对离散的语义元素进行连续的量化。以互补的方式，LLM“解码器”用于将嵌入转换回语言文本。<span><strong>将自然语言作为嵌入进行预处理，为探索不同语言模式与神经活动之间的相关性开辟了新方法。</strong></span>将自然语言数据与神经测量相关联，是朝着深刻理解人类大脑产生、感知、处理和解释语言的一步。自然语言文本的定量表证是计算分析中使用的行业通用中间形式，具有可重复性，可调整和可扩展增强的潜力。语言作为封装来自五种人类感官的信息的工具，提供了人类经验中多样化现象的量化表征。</p><p><br></p><p><strong><span>（2）图像标注</span></strong></p><p><br></p><p>图像自动标注领域再次启发了文本标注任务的创新，其中RETfound便是医学领域从图像到文本转换问题的一种创新解决方案<sup>[38]</sup>。作为一个基础模型，RETfound能够将广泛可用的视网膜图像标注为不同的疾病类别。它旨在加速包括白内障、中心性浆液性视网膜病变、糖尿病视网膜病变、青光眼、心力衰竭、黄斑功能障碍、心肌梗死、帕金森病、中风和黄斑变性等疾病的诊断过程。</p><p><br></p><p>模型架构基于大型视觉transformer框架：使用编码器生成高分辨率的嵌入空间，可以用来区分视网膜图像特征，这与LLMs在自然语言文本中编码语义的方式相似。<span><strong>这种模型的应用展示了LLMs在医学图像处理中的潜力，为医生提供了一种快速而准确的诊断工具，有助于提高医疗效率和患者护理质量。</strong></span></p><p><br></p><p>RETfound的解码器用于图像重建，而编码器则用于为下游疾病预测任务提取特征。RETfound通过自监督学习在160万张未标记的视网膜图像上进行了预训练。在这种范式中，AI模型无需任何额外的训练信息便可以学习数据集中查找模式。例如，如果一个神经网络在自监督学习任务中使用宠物图片作为训练集，模型很可能学会识别与猫、狗和其他流行宠物相对应的形状。模型知道如何区分不同类型宠物的图像，但它“不知道”我们称其中一组为“猫”，以及可能与图像中的宠物相关的其他信息。RETfound在预微调（pre-fine-tuned） 状态下也是如此：<span><strong>它可以区分视网膜扫描图像中看到的不同变异，这种能力使其能够针对特定疾病检测任务进行微调。</strong></span></p><p><br></p><p>这种微调是通过来自不同大小数据集的，特定专家提供的标签进行的。例如，用于标注“正常”、“黄斑变性”和“糖尿病视网膜病变”等条件的“OCTID”数据集，以及包含与353,157名患者在2008至2018年间就诊记录相关的眼科数据的Moorfields Eye Hospital-AlzEye数据集，被用于微调以优化RETfound进行湿性年龄相关性黄斑变性的预后评估。通过这样的全面训练，RETfound可以用来根据医疗专业人员生成的图像记录中的像素模式创建视网膜图像的文本描述。因此，像RETfound这样的模型旨在减轻专家的标注工作量，为使用LLMs进行类似目的的概念框架提供灵感。</p><p><br></p><p>图像格式的数据一方面可以用来捕捉物理世界，另一方面，也可以捕捉大脑神经元的活动。它们可以作为实验变量，例如在视觉刺激实验中使用的图片，以探索大脑扫描与这些刺激之间的联系。与图像格式不同，化学结构及其描述可以捕捉大脑化学、神经生理学、神经药理学和化学感觉刺激的关键方面。简化分子输入线性输入系统（SMILES Simplified molecular-input line-entry）是一种将化学结构表示为基于文本的对象的方法。SMILES最初是基于分子图的原则构思的，以严格规范的方式表示化学结构，非常适合机器处理<sup>[40]</sup>。</p><p><br></p></section><section powered-by="xiumi.us"><section><section><img data-ratio="0.3684992570579495" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHxX5FWErNBTEHoChb21jic2u30SrFBBJWnicGYL5KoshNP4Rt8700ze6Q/640?wx_fmt=png" data-w="673" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHxX5FWErNBTEHoChb21jic2u30SrFBBJWnicGYL5KoshNP4Rt8700ze6Q/640?wx_fmt=png"></section></section></section><section powered-by="xiumi.us"><section><p><strong>▷</strong><span> </span><span>图6:SMILES中配对分子图的示例</span></p></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>科学文献中包含了大量的化学名称，这些名称有时呈现标准化形式，但并非总是如此。通过适当的收集、整理和整合策略，可以构建一个结合化学名称和SMILES结构的语料库，用于训练大型语言模型（LLM）或微调基础模型，以探索化学结构与语义内容之间的潜在预测关系。如果能够实现这一点，进一步地，这个共同的嵌入空间可以连接到一个生成模型，该模型可以根据文本输入产生化学结构（例如，“我想看到能够进入人类中枢神经系统的新化学结构”）。在不远的将来，这样的多模态LLM可能成为科学家的宝贵伙伴，<span><strong>增强生成具有目标属性的全新分子的创造性过程，无论是物理、化学感知还是药理学属性</strong></span>。</p><p><br></p><p>另一个引人注目的应用是在SMILES（化学品的简化分子输入线性表示系统）和自然语言之间建立的共同嵌入空间，这不仅适用于单一化学物质的分析，也能扩展到化学混合物的研究。正如自然语言中词语和短语的解释会受到其上下文的显著影响一样，化学感知刺激中存在的气味分子（它们自然以混合物形式出现）的感知，也会受到其他混合物成分的组合和浓度的影响。此外，小分子如神经递质、激素、药物和毒素通常与其代谢物、杂质和其他生物分子共同作用。这些组合元素可以在其周围环境中产生生化和生理效应，例如结合到目标受体或调节信号转导通路的活性。</p><p><br></p><p>我们设想，<span><strong>一个经过SMILES和自然语言训练的LLM的共同潜在嵌入空间可以用来对化学品和混合物的复杂、依赖于上下文的多重作用进行导航，这对神经科学具有直接相关性</strong></span>。</p><p><br></p><p><strong><span>（3）描述能力</span></strong></p><p><br></p><p>除了高成本之外，标注任务面临的另一个问题是，依赖于预定本体或分类系统的标注将受到该描述系统的描述能力的限制。通常，执行标注任务的个体必须接受训练，以确保他们能够正确利用给定的本体对数据点进行分类，这是减少评分者差异性这一已知挑战的尝试。为了正确进行数据标注，所需的培训范围可能非常广泛，标注者必须是领域专家而非外行人。通过LLM编码器生成的嵌入，可以通过语义相似度测量或聚类等方法“翻译”为目标本体中的一系列术语。</p><p><br></p><p>如果不进行翻译，LLM给出的嵌入提供了基于本体的分类所无法提供的高语义粒度。这种特异性对于任何研究者在记录与特定实验直接相关的不同结果时都极为宝贵，因为它使得在与特定实验直接相关的分类方式上具有灵活性。</p><p><br></p><p>举一个简单的假设性例子，<span><strong>人们可以（1）从通过文本记录的注释标签或其他实验变量生成语义嵌入，（2）从目标本体中存在的术语生成嵌入，或（3）计算两组嵌入之间的余弦距离，以识别每个基于文本的实验变量与来自目标本体的“最近邻”术语</strong></span>。虽然这种方法可能无法达到领域专家的准确性水平，但它在分辨率上的不足通过客观性和操作一致性得到了补偿，这提高了大规模注释的可扩展性和可重复性。另一方面，LLM产生的嵌入也为研究人员提供了一种通过聚类或更复杂的技术来分析注释数据集的手段，从而得以识别新的分类系统。</p><p><br></p><p><span><strong>理想情况下，即使在没有与领域专家紧密合作的情况下，我们很快就能通过LLM进行专家级别的注释。</strong></span>更有趣的是，一旦证明了LLM能够以与专家相当或更优的性能应用现有的本体进行注释，我们就可以转向“专家LLM”来帮助识别和验证新术语和本体，这些术语和本体是通过数据驱动的方式得出的。同时，我们还可以借此机会检查基于LLM的注释结果，挑战那些由有限启发式设计的传统分类系统。</p><p><br></p><p>基于规则的解决方案虽然依赖明确的预定义标准，但在处理庞大且复杂的数据集时，黑箱式AI解决方案——尽管其决策过程不透明——通常能够展现出卓越的表现，实现传统方法难以匹及的预测准确性。将LLM辅助注释作为一种补充方法，将其与传统的自上而下的方法（例如，由领域专家手动分类）和基于规则（例如，预定义算法对数据点分类）的解决方案相结合，是我们可以同时利用专家经验带来的知识和LLMs从数据中获得的新见解的一种方式，这是一种真正能够“为自己说话”的数据形式。</p><p><br></p><p>LLMs被喻为变色龙*，具备“角色扮演”的能力<sup>[43]</sup>。它们可以采取已知人物或具有特定特征（个性和写作风格）的人物个性，例如夏洛蒂·勃朗特、卡尔·萨根或神经科学家。这种能力可以以多种方式利用。在某些注释任务中，与所有评估者都具有相同背景的评估小组相比，征求跨学科专家小组的意见可能更为有益。若干个LLM可以并行地在注释任务中扮演不同的角色，类似于人类评分者的分组。LLMs可以被要求采取不同专家、个性类型、职业、年龄和文化背景的立场来进行思考和评估。LLMs不仅解决了个体主观性对注释任务的影响，而且同时能够表达和操纵这种主观性。LLMs可以消除人类注释者所经历的短暂情感状态的波动，如果需要，它们可以在可控和可重复的方式中引入这些波动。</p><p><br></p></section><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><p><span>*https://karpathy.ai/lexicap/0215-large.html</span><br></p></section></section></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p><strong><span>描述神经科学研究以及主观体验的语言存在许多不一致之处。这些差异性助长了不同研究人员之间对注释解释的分歧。</span></strong>一致的语义嵌入空间的普遍性能够捕获和操纵模糊或主观的语言。关键的是，这些表征在实验室或其他研究和分析环境下是完全可重复的；只要对同一任务使用相同的LLM，并使用相同的模型参数集合。从科学研究的实际角度来看，这一特点应该对通过LLMs自动注释数据集的注释数据的共享性产生重大影响，有希望扩大LLMs自动注释数据集的下游应用的广度和深度。</p><p><br></p><p>不同的个体可能会以不同的方式标注相同的数据，甚至同一注释者在不同时间给出的回答也可能会有所变化。LLMs提供了一种更稳定和一致的标注。<span><strong>由于这些大型模型是基于广泛的数据集进行训练，不受个人主观体验的影响，它们能够在捕捉细致的上下文环境时替代人在手动标注任务中的主观性。</strong></span>训练后的LLMs可以被视为所有互联网用户平均思维的一种近似，即“众包思维”，因为它们的训练语料库的大部分来源于互联网。如果基础模型似乎没有捕捉到足够的细节以完成特定任务，它可以通过微调来近似基于特定网站或互联网用户子集的平均思维。</p><p><br></p><p>手动进行数据标注的过程通常包含主观性元素，特别是当被标注对象基于主观体验时在对《阿甘正传》中的场景进行注释的任务里，学生们需要标注他们所感知到的电影中演员表达的情绪。这项任务首先要求对电影中描绘的情感进行主观解释，再加上情感体验本身的高度主观性。studyforrest数据集还包括每个场景发生的物理位置的注释。尽管如“夜晚”与“白天”、“室内”与“室外”的标注主要基于具有电影学术背景的两位领域专家做出的客观判断，但在这个过程中仍然留有主观解释的空间，例如将“白天”定义为任何由阳光照亮的场景，而不是其他决定因素一样。</p><p><br></p><p><span><strong>LLMs能够在主观现象和客观测量的世界之间实现调和。</strong></span>通过LLM嵌入表征的语义实体，保留了文本中的离散主观或上下文意义，使其能够以一致的方式与其他文本进行比较。例如，想象一下从社交媒体帖子中收集的句子，用于自动注释情感标签，以便用于训练一个能够从用户帖子中预测情绪的NLP模型。无论每个设想的句子有多么独特，它们与“热情”、“沮丧”、“怀旧”或“平静”等术语对应嵌入之间的距离都可以用统一的方式计算。由于LLM训练语料库捕获了大量描述主观现象的文本，LLMs产生的更稳定和一致的注释，可以轻松地用于表征基于主观体验的数据元素，而无需将主观的人类判断作为注释过程的一部分。</p><p><br></p><p><span><strong>使用LLMs自动化注释任务并不是渐进式的改进，而是一种革命性的方法升级，可以颠覆主流实践，有望终结受到主观性和其他形式的特质所带来的限制。</strong></span>以注释一系列日记条目中的情感为例，如果任务交给一组人类注释者，一个人可能会根据他们的个人经验和文化背景将一段文字标记为“悲伤”，而另一个人可能会看到它为“反思”或“怀旧”然而，由于LLMs是自回归的、状态依赖的，并且具有温度等超参数（参见前一节“大型语言模型解决方案的数据科学视角”），它们在处理相同提示时的输出虽不尽相同，但如果实验条件保持一致，其答案主要限制在语义空间的一个狭窄区域内。通过这种方式，LLM可能提供人类注释者无法匹配的客观性和一致性。</p><p><br></p></section><section powered-by="xiumi.us"><section><img data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHLHrpstZTzJSIyrRZicMa3NlCErMbBiaQcHia0rUx876hHX819yGhtupFA/640?wx_fmt=png" data-ratio="0.43902439024390244" data-w="369" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHLHrpstZTzJSIyrRZicMa3NlCErMbBiaQcHia0rUx876hHX819yGhtupFA/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><section><p><strong>LLM在文本摘要和知识整合中的应用</strong><br></p></section></section><section powered-by="xiumi.us"><p><br></p></section><section powered-by="xiumi.us"><p>神经科学这个广泛的领域涉及从物理学到心理学等多个学科。这个极具跨学科性的领域产生了大量相对独立的实验发现，仅靠人力整合这些发现可能会显得力不从心。此外，该领域的宽广常常导致研究者在其子领域内孤立工作，专注于狭窄的研究领域，从而可能错过与其他子学科的交叉融合机会。也可能存在某些任务超出了人类认知能力，包括阅读包含大量数据点的实验结果，或提炼过去一年所有主要科学出版物的内容。在这些情况下，LLMs可以帮助研究人员获取大量文本中的信息，这些文本如果仅靠研究阅读来吸取其中信息，在短时间内可能会是很具挑战性的。</p><p><br></p><p>LLMs的能力超越了典型的文本摘要任务，其中收集的文本以人类可读（尽管冗长）的自然语言呈现。但LLM嵌入为主观文本提供了客观的量化，以解决语言歧义并给出标准化的输出。这些基于主观性的文本可以是简单的词语或短语，如用于捕捉《阿甘正传》中演员表现的情感<sup>[33]</sup>，或描述气味或风味化合物的化学感知<sup>[44]</sup>。它们还可能更为复杂，就像迷幻研究中使用的文本那样，描述迷幻药物及其对大脑和意识影响的研究。</p><p><br></p><p>“迷幻体验”这个常用表达方式暗示了不同体验之间的一致性。实际上，迷幻体验充满了细微差别和变化，部分根源于药物使用者的心态和环境，部分根源于药物之间的精神药理学差异。理解决定迷幻药物使用者观察到的细微差别的潜在因素，应该有助于我们了解是否可以利用某些药物或主观效果的类型来治疗特定状况，就像通过摄取赛洛西宾（psilocybin）和MDMA所提供的不同的体验在治疗强迫症和创伤后应激障碍方面所显示的早期成功，正是这种探索的实证。</p><p><br></p><p>为了研究这些细微差别，最近的一项研究使用了自然语言处理技术来分析来自迷幻药物使用者的6,850份“体验报告”（图7）。研究的目标是建立主观体验、27种不同药物，以及人类大脑中表达的40种相关神经递质受体之间的联系。这项研究的结果包括通过典型关联分析（CCA）得出的详细词汇列表，该列表按语义维度相关性排名，捕捉了体验报告中的主要主题。</p><p><br></p></section><section powered-by="xiumi.us"><section><section><img data-ratio="0.5652173913043478" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHCXcyKK4ia7FxCTiaeM2vNQpN1uw7VoJJDHKtzAx2owpJVSlxjo3KK5VA/640?wx_fmt=png" data-w="759" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHCXcyKK4ia7FxCTiaeM2vNQpN1uw7VoJJDHKtzAx2owpJVSlxjo3KK5VA/640?wx_fmt=png"></section></section></section><section powered-by="xiumi.us"><section><p><strong>▷ </strong><span><span>图7:使用NLP进行多模态受体-文本整合，揭示迷幻药物体验的机制基础分析。</span></span></p></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>人类解读由数千个词以特定顺序捕捉的复杂主题相当困难。CCA提供的排名列表中的每个词都带有可能被主观解释。由相邻术语提供的上下文以及列表不同子部分（即前1%与前5%）捕获的一般意义转变，进一步拓宽了潜在解释的范围。尽管结果以密集的高亮词汇列表呈现，但LLM可以无缝地从这些词集中抽象出语义核心主题，推导出由迷幻药物引发的主观效果的共享高层次类别。这些高层次类别随后可用于开拓新药发现平台，产生关于实验治疗方法的假设，寻找具有针对性主观效果的新迷幻药物，以治疗特定状况。<span><strong>未来LLM的应用展示了研究人员从复杂、非结构化数据中获取洞察的新机遇，尤其是在人类难以单独应对这些数据的情况下。</strong></span></p><p><br></p><p><span><strong>面向医学的LLMs，如Meta的PMC-LLaMA<sup>[46]</sup>，提供了一个有希望的解决方案，用于筛选大量文本来源，综合其意义和信息价值。通过收集和总结不同来源的信息景观，这些模型提供了触及甚至理解了复杂主题的本质。</strong></span>具体来说，PMC-LLaMA旨在通过训练庞大的语料库（480万篇生物医学学术论文、3万本医学教科书，以及202M个医学问答对、决策理由和对话）来支持用户导航广阔的医学信息。PMC-LLaMA在零样本评估医学知识提示时产生了合理且连贯的回应，例如，回答患者关于尿路感染的问题，以及关于微生物学和药理学的深入问题。当被问及涉及结核病和激素避孕药物相互作用的多项选择题时，PMC-LLaMA正确指出了药物相互作用的机制，并详细阐述了得出答案的理由（通过抗生素利福平诱导CYP3A4，导致激素避孕药物浓度降低，最终增加了意外怀孕的可能性）。</p><p><br></p><p>PMC-LLaMA强调了数据驱动方法在专业领域的有效性以及领域特定模型调整的价值。这种对提示查询的令人印象深刻的回应，代表了机器辅助人类智能的场景，其中LLMs可以被定制为有效地在专业领域教育用户，突显了这些模型改造社会的潜力和开发领域特定模型的重要性。</p><p><br></p><p>作为日常生活中另一个具体的例子，准备考试的医学生可以查询PMC-LLaMA等模型，获取特定主题的信息，以更高效的时间覆盖更广泛的材料。正如工业自动化释放了工人，让他们有更多时间去完成其他任务一样，我们可以预期LLMs的发展将呈现类似的机会。</p><p><br></p><p>然而，并非所有的改进都将仅仅是改善生活；许多应用，如可以访问患者电子健康记录的交互式LLM，可能具有挽救生命的潜能。不幸的是，Rodziewicz等人最近的一项统计调查估计，每年约有40万住院的美国患者经历某种可预防的伤害，其中大约四分之一的案例导致死亡。在医学领域，<span><strong>AI的潜在救命作用主要体现在几个方面：例如（1）减轻医疗专业人员的工作负担，使他们能够更有效地评估和治疗患者，以及（2）作为早期预警系统，提醒可能的不良事件。</strong></span></p><p><br></p></section><section powered-by="xiumi.us"><section><section><img data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66gZqibVA03xSR5KcjLvKfRM4sxPdoBT03JicenU3KFicpjiaJV27HeIGfksYJqqFvYzrp3icrkl6RiaPvIA/640?wx_fmt=png" data-ratio="0.4462809917355372" data-w="363" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66gZqibVA03xSR5KcjLvKfRM4sxPdoBT03JicenU3KFicpjiaJV27HeIGfksYJqqFvYzrp3icrkl6RiaPvIA/640?wx_fmt=png"></section></section></section><section powered-by="xiumi.us"><section><p><strong>多来源和多模态语言模型的整合</strong></p></section></section><section powered-by="xiumi.us"><p><br></p></section><section powered-by="xiumi.us"><section><p>在过去的几十年里，神经科学已经扩展到越来越细分的研究活动领域。例如，阿尔茨海默病（AD）在几个基本上相互独立的研究社区中被研究。研究人类群体中AD病因的流行病学家并不经常与遗传学家、实验神经学家、脑成像研究者或动物实验研究者进行交流。研究与AD相关的全基因组风险变异的遗传学家，也不一定会参考或整合来自这些其他神经科学社区的现有知识。致力于研究AD大脑结构和功能差异的成像神经科学家，在设计和解释他们的研究时，也不一定会考虑流行病学人群分层的方面。每个AD研究社区似乎都在自己的“泡沫”中运作，形成了各自的杰出科学家群体，自己常讨论的假设池，以及自己独特的知识积累过程，且每年发表着大量的研究成果。</p><p><br></p><p>鉴于每年研究产出的不断增加，单个研究者越来越难以阅读所有这些论文。神经科学的许多研究活动领域以类似的方式被分割。这种知识碎片化可能是21世纪科学事业面临的最大挑战之一。<span><strong>现在，LLMs提供了一个机会，可以整合并翻译来自单一神经科学主题多个互补视角的日益增长的知识库。</strong></span></p><p><br></p><p>LLMs也开始针对医学领域进行定制，如在医学考试和生成记录等任务中取得了有希望的结果。迄今为止，医学中的AI通常基于计算机视觉，对文本、语音和其他类型信息的整合有限。然而，通过LLMs对各种数据源的总结和整合，为推进AI辅助医疗专业人员的实践带来了巨大的希望。生物传感器、基因组档案、医疗记录、患者自述、代谢数据和其他实验室检测，都成为了构建针对个体患者定制的多模态AI诊疗路径的潜在数据源<sup>[48]</sup>。这种AI解决方案的潜力巨大，因为它可能对患者的生活和医疗专业人员的表现产生直接影响，，尽管这一目标还未完全实现<sup><span>[49]</span></sup>。</p><p><br></p><p>目前，应用LLMs减轻医疗专业人员文档工作量的可能性也正受到医学界的广泛关注。尽管使用LLMs在医学和医学研究中的伦理问题开始被讨论<sup>[50]</sup>，但现在越来越明显的是，LLMs可以作为辅助工具，有效减轻目前占用大量人力和时间的医疗流程，如电子健康记录的创建和处理，以及疾病的诊断和预后等多个方面。</p><p><br></p><p>作为下一个圣杯，哪些非文本数据模式可以赋予LLMs行动力？广义上，LLMs可能是第一个能够无缝结合结构化和非结构化信息的技术，无论信息的规模多大或是多么动态。此外，ChatGPT和类似的LLM变体已经成功地将来自多种语言、地理和文化的分散文本源聚合到一个模型实例中，这表明LLMs在多语言文本处理中的强大能力。</p><p><br></p><p>LLMs在弥合不同信息类型间差异，尤其是计算机视觉（即图像）与语言（即文本）之间的差异方面展现出了巨大潜力。机器学习社区的一个近期例子是，Alayrac等人<sup>[35]</sup>展示了如何通过包含额外的模态信息来改进语言模型。Flamingo模型便是在包含文本和图像信息的互联网上的大规模多模态语料库上训练的，它的小样本学习能力使其能够适应包含图像和视频材料的各种任务。模型可以根据特定任务的例子进行提示，基于视觉条件的自回归文本生成，在许多场景中提供了实际益处。在神经科学领域，一个早期的例子是尝试使用模型仅从大脑活动测量重建自然图像的研究<sup>[51]</sup>。<br></p><p><br></p><p>此外，DALL-E/CLIP（由OpenAI在2021/22年提供）是生成性AI中文本-图像融合的早期例子，最初该模型基于GPT-3变体开发，旨在从用户提示生成更真实的图像。这个多模态融合引擎可以合成各种形式和风格，如逼真的自然图像、类似绘画的艺术和符号，以及设计方案的内部模型，调用真实和想象的对象、场景和人物，且无需众多训练示例（零样本学习）。其组件CLIP（对比语言-图像预训练）在互联网上约4亿对图像和文本标题上进行了训练，用于在DALL-E生成的图像中选择最佳输出。CLIP将计算机视觉和NLP结合在一个单一网络中，深度处理、分类和生成大量图像的文本注释。它不需要严格的任务特定训练，可以将其知识泛化到新的、未曾遇到的任务。</p><p><br></p><p>在神经科学背景下，未来的LLM框架可能会潜在地摄取多种形式的“图像”，如结构和功能MRI脑成像、PET、fNIRS，以及更广泛的EEG/MEG衍生脑图像。因此，一个重要的未来研究方向是探索DALL-E/CLIP和类似新兴技术，能在多大程度上成功地从自然图像扩展到包含大脑“图像”的多模态分析中。</p><p><br></p><p>例如，NeuroSynth数据库展示了一种自下而上的方法<sup>[52]</sup>，它自动提取了超过3,000篇脑成像任务实验文章的3D图像空间激活坐标，以及这些文章的全文。这一举措已经通过一个用户查询的网络界面为神经科学界提供了价值。与之平行的研究是BrainMap<sup>[53.54]</sup>数据库，其以自上而下的方式，围绕心理学类别构建了脑成像实验的人类本体论。对认知现象的描述系统是由人类领域专家手工设计的。</p><p><br></p><p>在这项研究中，同样也已经尝试了对图像描述对进行聚合，可视作训练或完善最先进的多模态LLMs的一个有吸引力的起点。一个想法是基于两个数据库中可用的研究、专家定义和全文注释相互补充，整合NeuroSynth和BrainMap，可能启用LLM支持的查询服务，也许还能跨越两种类型的大脑图像元信息进行推理。更广泛地说，旨在跨越内容类型界限的这些研究方向特别有前景，因为LLMs提供了一个前所未有的机会，将结构化和非结构化信息融合于一个统一的框架中。</p><p><br></p><p>在未来几年，<strong><span>神经科学家可以系统地研究哪些与大脑相关、适合LLM涌现的功能模式的信息？又哪些类型的神经科学信息可以被标记，以及如何标记？</span></strong></p><p><br></p><p>最近的LLM研究显示了利用嵌入的氨基酸块、基因及其mRNA转录本、细胞和细胞类型、表型和疾病状态的潜力。LLMs可能还能处理标记化的大脑区域活动实例、白质纤维通路、大脑结构变化位置、EEG/MEG中的频率带变化或钙成像。</p><p><br></p><p>经由这些能力，神经科学家可以将数据集中的序列语义和生物学视角结合起来，形成对大脑的统一视角。这一目标的实现可能需要对模型架构进行创新，以表征这些信息层。或者，我们可以使用预训练的LLMs的输出作为一种编码特定信息模式的蒸馏形式，将其整合到随后训练的较小模型中，以实现最终的研究目标。具体来说，来自英国生物银行和其他大型数据集的数据集允许LLM将基因变异信息和其他分子数据与各种人类健康信息关联起来。</p><p><br></p><p>作为神经科学这一高度跨学科努力的核心愿望，<strong><span>LLMs可以帮助我们弥合不同神经科学社区之间的鸿沟，并使我们形成能够整合多来源知识的NLP模型。</span></strong></p><p><br></p></section></section><section powered-by="xiumi.us"><section><section><img data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66ia7QDJLgwvG7n6VBU0kwiaOzpJsS44xk2Y6vrrJOzBMHktyxD0Tk1S3ibsVKsawjLnm4HW4OtX98oqQ/640?wx_fmt=png" data-ratio="0.4358288770053476" data-w="374" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66ia7QDJLgwvG7n6VBU0kwiaOzpJsS44xk2Y6vrrJOzBMHktyxD0Tk1S3ibsVKsawjLnm4HW4OtX98oqQ/640?wx_fmt=png"></section></section></section><section powered-by="xiumi.us"><section><p><strong>大模型作为克服当前概念危机的认知纽带</strong></p></section></section><section powered-by="xiumi.us"><p><br></p></section><section powered-by="xiumi.us"><p>LLMs可能提供一个替代工具包，该工具对于汇总和编辑神经科学研究者用来解析大脑功能的人类构建概念非常有价值。重要的是要认识到，特别是在经典的假设驱动研究中，整个研究努力都依赖于预先假设的认知和神经术语的有效性，这些术语用于阐述实验研究条件。然而，许多频繁使用的心理学或认知术语定义脆弱，无法在自然界中直接观察到。许多由人类专家确定的神经科学概念可能并不代表“自然分类”，因为它们并没有在自然界中划分出对立独立的神经回路。</p><p><br></p><p>大多数认知过程的概念在神经科学作为一个连贯学科出现之前（大约在20世纪中叶）就已经被创造出来，那时大脑功能才开始被理解。此外，某些行为或认知概念可能只在健康受试者精心设计的实验或临床条件（如具有局部脑损伤的患者<sup>[55]</sup>）中出现。根据这种观点，神经认知过程可以在受试者参与特定实验任务时被分解，作为揭示大脑与行为之间映射的途径。<strong><span>也许现在是时候用一种有规律的数据驱动方法，来测试这些概念的有效性了。</span></strong></p><p><br></p><p>神经科学家在描述大脑现象时遭遇的复杂性，与路德维希·维特根斯坦在其著作《哲学研究》中所提出的观点紧密相关。维特根斯坦晚年认为，人类语言本身所带来的混淆，是许多哲学问题的根本来源。例如，在心理学中，甚至像“认知”和“情感”这样的简单词汇都缺乏一个普遍认同的定义<sup>[56-57]</sup>。此外，常在心智理论中提及的大脑网络，即从他人视角进行思考的能力，也始终参与了一系列多样化的心理过程，包括道德思考、自传体记忆检索和空间导航等<sup>[58-60]</sup>。我们目前遗留的神经认知框架，可能没有指向正确的方向<sup>[61]</sup>。</p><p><br></p><p>例如，我们为什么隐含地期望威廉·詹姆斯的杰作（《心理学原理》，1890年）中的术语和概念，能够代表大脑中特定的机制？更进一步的是，当我们遇到难以调和的发现时，我们有时会倾向于创造一个新术语，而不是真正深入问题的核心。</p><p><br></p><p>许多神经科学研究采取自外而内的方法：他们首先创造概念，然后试图在大脑活动中找到这些概念的对应或描述<sup>[61]</sup>。这与一些作者所说的“新颅相学”密切相关， 后者是一种简化主义方法或“过度定位”，试图将术语映射到大脑的局部地理区域<sup>[62]</sup>。<strong><span>虽然现代神经成像显示，在某些任务中特定的大脑区域确实更活跃，但鉴于大脑的高度互联性以及多个认知功能的网络分布特点，试图为复杂的功能找到单一的“定位点”可能极具误导。</span></strong></p><p><br></p><p>研究重点应该放在大脑的实际反应上，而不是人类发明的术语本身。的确，正是是大脑中的神经认知过程产生了行为和认知。简而言之，心理术语如何以及在多大程度上映射到区域大脑反应，仍然是难以捉摸的，反之亦然<sup>[62-64]</sup>。出于这些原因，一些作者提出神经科学在数据上越来越丰富<sup>[65]</sup>，但在理论上仍然贫乏，指出了迫切需要新的研究假设生成手段。</p><p><br></p><p>关于大脑疾病的定义，尤其是精神病学中的术语，也可以提出类似的观点。相同的概念并不唯一地与相同的机制相关，相同的机制也不经常对应这一个明确的诊断实体。这一认识可能是为什么相同的药物类别经常有助于缓解名义上不同的精神状况症状的原因之一。</p><p><br></p><p>DSM-5和ICD-10手册是根据精选专家的意见对精神病进行分类的。此外，资助机构只有在研究人员的提案理由和预期结果坚定地基于这些人类制造的诊断类别时，才会承诺资助。然而，越来越清楚的是，即使在遗传水平上<sup>[66]</sup>，基础生物学中的病理生理过程也具有相当高异质性，且相互存在重叠。因此，当今对精神健康状况的描述系统虽然有助于实践医生之间的交流，但在研究的生物学有效性和临床护理的预测性方面，仍然显得力不从心。</p><p><br></p><p>尽管神经科学中现有描述系统存在明显的不足，但很少有尝试以自下而上的方式构建这样一个语义概念系统。在一项开创性研究中，研究人员设计了一个基于数据的方法，来构建神经认知类别的框架<sup>[67]</sup>，该框架汇集了大约20,000篇人类脑成像论文的信息。利用超过25年脑成像研究积累的数据宝库，NLP算法挖掘了研究文章的语义内容，并将其与来自功能脑扫描（fMRI，PET）的60多万个拓扑位置相结合。这种方法同时平等关注了语义原则和神经活动原则，允许研究者以整体方法系统地整合大脑和行为。</p><p><br></p><p>此外，这种方法还有助于克服神经科学界长期困扰的一个问题——如何从概念出发推理大脑活动（前向推理）以及如何从大脑活动推断概念（后向推理）<sup>[62]</sup>。<strong><span>在实证验证分析中，这种“计算本体论”被证明比神经科学和精神病学中广泛接受的描述系统，在重现术语与功能链接方面，对新的、未见过的研究成果具有更好的适应性。</span></strong></p><p><br></p></section><section powered-by="xiumi.us"><section><section><img data-ratio="1.0013175230566536" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSH9tvcT5vTiaJE3OCPkfXW8DMVmRRARcw0SnwXtRYjZK9Mt7gYdaIDCVw/640?wx_fmt=png" data-w="759" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66jzibItV1aBxMXLy7VTGicNSH9tvcT5vTiaJE3OCPkfXW8DMVmRRARcw0SnwXtRYjZK9Mt7gYdaIDCVw/640?wx_fmt=png"></section></section></section><section powered-by="xiumi.us"><section><p><strong>▷ </strong><span><span>图8:NLP工具以完全底层的方式整合现有关于人类认知的概念</span></span></p></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p>综合来看，我们用来描述世界的叙事和故事塑造了我们设计神经科学实验和解释发现的方式。在神经科学中，真正的进步需要对词语使用、语言卫生（language hygiene）和概念化变体有特别的敏感性。在未来，<strong><span>由LLM赋能的神经科学中，我们可能能够将心理学固定术语，基于科学证据重新放到新架构中，而不是延续前一个历史时期的遗留术语。</span></strong></p><p><br></p><p>新兴的LLM技术可以激发基于生物学的大脑疾病分类学的，具有重大意义的重新定义，从而<strong><span>跨越诊断边界，进入一个基于证据的精神医学新时代，而不是仅仅依赖于特定专家的判断。</span></strong>正如维特根斯坦所说，“我语言的极限就是我世界的极限。”<sup>[68]</sup></p><p><br></p></section><section powered-by="xiumi.us"><section><section><img data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66ia7QDJLgwvG7n6VBU0kwiaOzoBPicicMdDC50jZWiaibRHBqia64DAmvameflzgjMdMqtYn3F6SCNbcX1uA/640?wx_fmt=png" data-ratio="0.44173441734417346" data-w="369" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66ia7QDJLgwvG7n6VBU0kwiaOzoBPicicMdDC50jZWiaibRHBqia64DAmvameflzgjMdMqtYn3F6SCNbcX1uA/640?wx_fmt=png"></section></section></section><section powered-by="xiumi.us"><section><p><strong>结论</strong></p></section></section><section powered-by="xiumi.us"><p><br></p></section><section powered-by="xiumi.us"><p>在过去的5到10年里，生物学已经转变为一门“可计算”的学科。例如，大规模基因数据库与定向CRISPR基因编辑和机器学习分析相结合，使生物学更接近于一个工程学科。我们生成生物分子数据的能力远远超过了我们从这些系统中真正获得理解的雄心——正如John Naisbitt所写<sup>[69]</sup>，<strong><span>今天的神经科学家实际上是“被信息淹没，却又渴望着知识”。</span></strong></p><p><br></p><p>LLMs为研究者提供了新的机遇。这类模型表明，纯粹的统计暴力可以帮助研究者通过阅读和生成生物学来揭开大脑和疾病的神秘面纱，通过构建知识框<span>架，解锁前所未有的大规模信息整合和研读模式。基础模型可能会从神经科学领域中提取、协同和合成知识，跨越孤立的“学科间隔”，这项任务可能会（也可能不会）超越人类的理解范</span>畴。神经科学家需要接受并拥抱这样一个令人不安的可能性：<strong><span>人类大脑作为一个生物系统，其复杂性可能超出了人类智能独立理解的范畴，唯有借助AI工具处理大数据，我们才可能理解它。</span></strong></p><p><br></p><p>从更广泛的社会角度来看，工业革命主要影响了蓝领工作。相比之下，当前的LLM革命可能会主要影响白领工作，包括神经科学研究人员的工作。事实上，LLMs的惊人效能已被一些风险投资家和投资者与火的发现、电力的应用或互联网的诞生相提并论，这些发明都极大地推动了人类社会的进步。LLM是否真就能改变世界，让我们拭目以待。</p><p><br></p></section><section powered-by="xiumi.us"><section><img data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hOuC4CDbz41JswsKHVHPGNQXqLy9YvTUtCGwr9ECEMYGBkrOX2WmSSPx9op1fic82VAQSGpKYeeqA/640?wx_fmt=png" data-ratio="0.2660996354799514" data-w="823" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hOuC4CDbz41JswsKHVHPGNQXqLy9YvTUtCGwr9ECEMYGBkrOX2WmSSPx9op1fic82VAQSGpKYeeqA/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><section><p><span>1. Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., and Dean, J. (2013).</span></p><p>Distributed representations of words and phrases and their compositionality. Adv. Neural Inf. Process. Syst. 26. https://papers.nips.cc/paper_files/</p><p>paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf.</p><p>2. Le, Q., and Mikolov, T. (2014). Distributed representations of sentences</p><p>and documents. PMLR 32, 1188–1196.</p><p>3. Conneau, A., Kiela, D., Schwenk, H., Barrault, L., and Bordes, A. (2017).</p><p>Supervised learning of universal sentence representations from natural</p><p>language inference data. Preprint at arXiv. https://doi.org/10.48550/arXiv.1705.02364.</p><p>4. McCann, B., Bradbury, J., Xiong, C., and Socher, R. (2017). Learned in</p><p>translation: Contextualized word vectors. Adv. Neural Inf. Process.</p><p>Syst.. https://dl.acm.org/doi/10.5555/3295222.3295377.</p><p>5. Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013). Efficient estimation</p><p>of word representations in vector space. Preprint at arXiv. https://doi.org/</p><p>10.48550/arXiv.1301.3781.</p><p>6. Pennington, J., Socher, R., and Manning, C.D. (2014). Glove: Global vectors for word representation. https://nlp.stanford.edu/pubs/glove.pdf.</p><p>7. Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar,</p><p>E., Lee, P., Lee, Y.T., Li, Y., and Lundberg, S. (2023). Sparks of artificial</p><p>general intelligence: Early experiments with gpt-4. Preprint at arXiv.</p><p>https://doi.org/10.48550/arXiv.2303.12712.</p><p>8. Goldstein, A., Zada, Z., Buchnik, E., Schain, M., Price, A., Aubrey, B., Nastase, S.A., Feder, A., Emanuel, D., Cohen, A., et al. (2022). Shared computational principles for language processing in humans and deep language</p><p>models. Nat. Neurosci. 25, 369–380. https://doi.org/10.1038/s41593-022-</p><p>01026-4.</p><p>9. Caucheteux, C., Gramfort, A., and King, J.-R. (2023). Evidence of a predictive coding hierarchy in the human brain listening to speech. Nat. Hum. Behav. 7, 430–441. https://doi.org/10.1038/s41562-022-01516-2.</p><p>10. Schrimpf, M., Blank, I.A., Tuckute, G., Kauf, C., Hosseini, E.A., Kanwisher,</p><p>N., Tenenbaum, J.B., and Fedorenko, E. (2021). The neural architecture of</p><p>language: Integrative modeling converges on predictive processing. Proc.</p><p>Natl. Acad. Sci. USA 118, e2105646118. https://doi.org/10.1073/pnas.</p><p>2105646118.</p><p>11. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez,</p><p>A.N., Kaiser, q., and Polosukhin, I. (2017). Attention is all you need. Adv.</p><p>Neural Inf. Process. Syst. 30.</p><p>12. Hassid, M., Peng, H., Rotem, D., Kasai, J., Montero, I., Smith, N.A., and</p><p>Schwartz, R. (2022). How much does attention actually attend? Questioning the Importance of Attention in Pretrained Transformers. Preprint at arXiv. https://doi.org/10.48550/arXiv.2211.03495.</p><p>13. Tay, Y., Dehghani, M., Abnar, S., Shen, Y., Bahri, D., Pham, P., Rao, J.,</p><p>Yang, L., Ruder, S., and Metzler, D. (2020). Long range arena: A benchmark for efficient transformers. Preprint at arXiv. https://doi.org/10.</p><p>48550/arXiv.2011.04006.</p><p>14. Bzdok, Danilo, and Yeo, B.T.T (2017). Inference in the age of big data:</p><p>Future perspectives on neuroscience. Neuroimage 155, 549–564.</p><p>15. Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., and Metzler, D. (2022). Emergent abilities</p><p>of large language models. Preprint at arXiv. https://doi.org/10.48550/arXiv.2206.07682.</p><p>16. OpenAI. (2023). GPT-4 Technical Report. Preprint at arXiv. https://doi.org/</p><p>10.48550/arXiv.2303.08774.</p><p>17. Kaplan, J., McCandlish, S., Henighan, T., Brown, T.B., Chess, B., Child, R.,</p><p>Gray, S., Radford, A., Wu, J., and Amodei, D. (2020). Scaling laws for neural language models. Preprint at arXiv. https://doi.org/10.48550/arXiv.</p><p>2001.08361.</p><p>18. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix,</p><p>T., Rozie`re, B., Goyal, N., Hambro, E., and Azhar, F. (2023). Llama:</p><p>Open and efficient foundation language models. Preprint at arXiv.</p><p>https://doi.org/10.48550/arXiv.2302.13971.</p><p>19. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D.d.L., Hendricks, L.A., Welbl, J., and Clark, A. (2022).</p><p>Training compute-optimal large language models. Preprint at arXiv.</p><p>https://doi.org/10.48550/arXiv.2203.15556.</p><p>20. Schaeffer, R., Miranda, B., and Koyejo, S. (2023). Are emergent abilities of</p><p>Large Language Models a mirage?. Preprint at arXiv. https://doi.org/10.</p><p>48550/arXiv.2304.15004.</p><p>21. Caballero, E., Gupta, K., Rish, I., and Krueger, D. (2022). Broken neural</p><p>scaling laws. Preprint at arXiv. https://doi.org/10.48550/arXiv.2210.14891.</p><p>22. Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q.,</p><p>Gesmundo, A., Attariyan, M., and Gelly, S. (2019). Parameter-efficient</p><p>transfer learning for NLP. PMLR 97, 2790–2799. https://proceedings.mlr.</p><p>press/v97/houlsby19a/houlsby19a.pdf.</p><p>23. Pfeiffer, J., Ruckle € ´ , A., Poth, C., Kamath, A., Vulic, I., Ruder, S., Cho, K.,</p><p>and Gurevych, I. (2020). Adapterhub: A framework for adapting transformers. Preprint at arXiv. https://doi.org/10.48550/arXiv.2007.07779.</p><p>24. Bapna, A., Arivazhagan, N., and Firat, O. (2019). Simple, scalable adaptation for neural machine translation. Preprint at arXiv. https://doi.org/10.</p><p>48550/arXiv.1909.08478.</p><p>25. Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.</p><p>(2019). Language models are unsupervised multitask learners. OpenAI</p><p>blog 1, 9.</p><p>26. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P.,</p><p>Neelakantan, A., Shyam, P., Sastry, G., and Askell, A. (2020). Language</p><p>models are few-shot learners. Adv. Neural Inf. Process. Syst. 33,</p><p>1877–1901.</p><p>27. Xiang, J., Tao, T., Gu, Y., Shu, T., Wang, Z., Yang, Z., and Hu, Z. (2023).</p><p>Language Models Meet World Models: Embodied Experiences Enhance</p><p>Language Models. Preprint at arXiv. https://doi.org/10.48550/arXiv.</p><p>2305.10626.</p><p>28. Berglund, L., Tong, M., Kaufmann, M., Balesni, M., Stickland, A.C., Korbak, T., and Evans, O. (2023). The Reversal Curse: LLMs trained on "A is</p><p>B" fail to learn "B is A".. Preprint at arXiv. https://doi.org/10.48550/arXiv.</p><p>2309.12288.</p><p>29. Brandes, N., Goldman, G., Wang, C.H., Ye, C.J., and Ntranos, V. (2023).</p><p>Genome-wide prediction of disease variant effects with a deep protein language model. Nat. Genet. 55, 1512–1522. https://doi.org/10.1038/</p><p>s41588-023-01465-0.</p><p>30. Cui, H., Wang, C., Maan, H., and Wang, B. (2023). scGPT: Towards Building a Foundation Model for Single-Cell Multi-omics Using Generative AI.</p><p>Preprint at bioRxiv. https://doi.org/10.1101/2023.04.30.538439.</p><p>31. Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O.,</p><p>Tunyasuvunakool, K., Bates, R., Zı ´dek, A., Potapenko, A., et al. (2021) Highly accurate protein structure prediction with AlphaFold. Nature 596,</p><p>583–589. https://doi.org/10.1038/s41586-021-03819-2.</p><p>32. Rives, A., Meier, J., Sercu, T., Goyal, S., Lin, Z., Liu, J., Guo, D., Ott, M.,</p><p>Zitnick, C.L., Ma, J., and Fergus, R. (2021). Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences. Proc. Natl. Acad. Sci. USA 118, e2016239118. https://doi.org/</p><p>10.1073/pnas.2016239118.</p><p>33. Yang, E., Milisav, F., Kopal, J., Holmes, A.J., Mitsis, G.D., Misic, B., Finn,</p><p>E.S., and Bzdok, D. (2023). The default network dominates neural responses to evolving movie stories. Nat. Commun. 14, 4197. https://doi.</p><p>org/10.1038/s41467-023-39862-y.</p><p>34. Ye, Z., Liu, Y., and Li, Q. (2021). Recent Progress in Smart Electronic Nose</p><p>Technologies Enabled with Machine Learning Methods. Sensors 21, 7620.</p><p>https://doi.org/10.3390/s21227620.</p><p>35. Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc,</p><p>K., Mensch, A., Millican, K., and Reynolds, M. (2022). Flamingo: a visual</p><p>language model for few-shot learning. Adv. Neural Inf. Process. Syst.</p><p>35, 23716–23736.</p><p>36. Sharma, P., Ding, N., Goodman, S., and Soricut, R. (2018). Conceptual</p><p>captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning. Proceedings of the 56th Annual Meeting of the Association</p><p>for Computational Linguistics. https://aclanthology.org/P18-1238/.</p><p>37. Thomee, B., Shamma, D.A., Friedland, G., Elizalde, B., Ni, K., Poland, D.,</p><p>Borth, D., and Li, L.-J. (2016). YFCC100M: The new data in multimedia</p><p>research. Commun. ACM 59, 64–73.</p><p>38. Zhou, Y., Chia, M.A., Wagner, S.K., Ayhan, M.S., Williamson, D.J.,</p><p>Struyven, R.R., Liu, T., Xu, M., Lozano, M.G., Woodward-Court, P., et al.</p><p>(2023). A foundation model for generalizable disease detection from retinal</p><p>images. Nature 622, 156–163.</p><p>39. Wagner, S.K., Hughes, F., Cortina-Borja, M., Pontikos, N., Struyven, R.,</p><p>Liu, X., Montgomery, H., Alexander, D.C., Topol, E., Petersen, S.E., et al.</p><p>(2022). AlzEye: longitudinal record-level linkage of ophthalmic imaging</p><p>and hospital admissions of 353 157 patients in London, UK. BMJ open</p><p>12, e058552.</p><p>40. Weininger, D. (1988). SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules. J. Chem. Inf.</p><p>Comput. Sci. 28, 31–36.</p><p>41. Bzdok, D., and Ioannidis, J. P. (2019). Exploration, inference, and prediction in neuroscience and biomedicine. Trends in neurosciences 42,</p><p>251–262.</p><p>42. Bzdok, D., Engemann, D., and Thirion, B. (2020). Inference and prediction</p><p>diverge in biomedicine. Patterns 1, 100119.</p><p>43. Shanahan, M., McDonell, K., and Reynolds, L. (2023). Role play with large</p><p>language models. Nature 623, 493–498. https://doi.org/10.1038/s41586-</p><p>023-06647-8.</p><p>44. Sharma, A., Kumar, R., Ranjta, S., and Varadwaj, P.K. (2021). SMILES to</p><p>smell: decoding the structure–odor relationship of chemical compounds</p><p>using the deep neural network approach. J. Chem. Inf. Model. 61,</p><p>676–688.</p><p>45. Ballentine, G., Friedman, S.F., and Bzdok, D. (2022). Trips and neurotransmitters: Discovering principled patterns across 6850 hallucinogenic experiences. Sci. Adv. 8, eabl6989.</p><p>46. Wu, C., Zhang, X., Zhang, Y., Wang, Y., and Xie, W. (2023). Pmc-llama:</p><p>Further finetuning llama on medical papers. Preprint at arXiv. https://doi.</p><p>org/10.48550/arXiv.2304.14454.</p><p>47. Rodziewicz, T.L., Houseman, B., and Hipskind, J.E. (2023). Medical Error</p><p>Reduction and Prevention. In StatPearls (StatPearls Publishing LLC.).</p><p>48. Hipp, R., Abel, E., and Weber, R.J. (2016). A Primer on Clinical Pathways.</p><p>Hosp. Pharm. 51, 416–421. https://doi.org/10.1310/hpj5105-416.</p><p>49. Acosta, J.N., Falcone, G.J., Rajpurkar, P., and Topol, E.J. (2022). Multimodal biomedical AI. Nat. Med. 28, 1773–1784. https://doi.org/10.1038/</p><p>s41591-022-01981-2.</p><p>62. Poldrack, R.A. (2006). Can cognitive processes be inferred from neuroimaging data? Trends Cogn. Sci. 10, 59–63. S1364-6613(05)00336-</p><p>0 [pii]. https://doi.org/10.1016/j.tics.2005.12.004.</p><p>63. Laird, A.R., Fox, P.M., Eickhoff, S.B., Turner, J.A., Ray, K.L., McKay, D.R.,</p><p>Glahn, D.C., Beckmann, C.F., Smith, S.M., and Fox, P.T. (2011). Behavioral interpretations of intrinsic connectivity networks. J. Cogn. Neurosci.</p><p>23, 4022–4037. https://doi.org/10.1162/jocn_a_00077.</p><p>64. Mesulam, M.M. (1998). From sensation to cognition. Brain 121 (Pt 6),</p><p>1013–1052.</p><p>65. Voytek, B. (2022). The data science future of neuroscience theory. Nat.</p><p>Methods 19, 1349–1350. https://doi.org/10.1038/s41592-022-01630-z.</p><p>66. Brainstorm Consortium, Anttila, V., Bulik-Sullivan, B., Finucane, H.K., Walters, R.K., Bras, J., Duncan, L., Escott-Price, V., Falcone, G.J., Gormley,</p><p>P., et al. (2018). Analysis of shared heritability in common disorders of</p><p>the brain. Science 360, eaap8757. https://doi.org/10.1126/science.</p><p>aap8757.</p><p>67. Beam, E., Potts, C., Poldrack, R.A., and Etkin, A. (2021). A data-driven</p><p>framework for mapping domains of human neurobiology. Nat. Neurosci.</p><p>24, 1733–1744. https://doi.org/10.1038/s41593-021-00948-9.</p><p>68. Wittgenstein, L. (1958). Philosophical Investigations (Basil Blackwell).</p><p>69. Naisbitt, J. (1988). Megatrends: ten new directions transforming our lives</p><p>(Warner Books).</p><p>70. Dziri, N., Milton, S., Yu, M., Zaiane, O., and Reddy, S. (2022). On the origin</p><p>of hallucinations in conversational models: Is it the datasets or the</p><p>models?. Preprint at arXiv. https://doi.org/10.48550/arXiv.2204.07931.</p><p>71. Strubell, E., Ganesh, A., and McCallum, A. (2019). Energy and policy considerations for deep learning in NLP. Preprint at arXiv. https://doi.org/10.</p><p>48550/arXiv.1906.02243.</p><p>72. Nadeem, M., Bethke, A., and Reddy, S. (2020). StereoSet: Measuring stereotypical bias in pretrained language models. Preprint at arXiv. https://</p><p>doi.org/10.48550/arXiv.2004.09456.</p><p>73. Liu, F., Bugliarello, E., Ponti, E.M., Reddy, S., Collier, N., and Elliott, D.</p><p>(2021). Visually grounded reasoning across languages and cultures. Preprint at arXiv. https://doi.org/10.48550/arXiv.2109.13238.</p></section></section></section></section></section><section powered-by="xiumi.us"><section><img data-ratio="0.1638888888888889" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hOuC4CDbz41JswsKHVHPGNwiaVkpBRqou5JltXicB4K7ibGL9xI27qKgLyoG2clialX1HN0WibsumlaJA/640?wx_fmt=png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hOuC4CDbz41JswsKHVHPGNwiaVkpBRqou5JltXicB4K7ibGL9xI27qKgLyoG2clialX1HN0WibsumlaJA/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><section><img data-ratio="0.24537037037037038" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66ia7QDJLgwvG7n6VBU0kwiaOza7MqOAEhsViashzYBBxweOUAtxSwcia608DmDhDtuiakfpoRQick3icdObA/640?wx_fmt=jpeg" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66ia7QDJLgwvG7n6VBU0kwiaOza7MqOAEhsViashzYBBxweOUAtxSwcia608DmDhDtuiakfpoRQick3icdObA/640?wx_fmt=jpeg"></section></section><section powered-by="xiumi.us"><section><section><img data-ratio="0.24537037037037038" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66ia7QDJLgwvG7n6VBU0kwiaOzyyIBpicvR0ibeWBtVbfrQqiaANiahjFia6icfA9ibiaiatia11L5UvcCBjOibzg0w/640?wx_fmt=jpeg" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66ia7QDJLgwvG7n6VBU0kwiaOzyyIBpicvR0ibeWBtVbfrQqiaANiahjFia6icfA9ibiaiatia11L5UvcCBjOibzg0w/640?wx_fmt=jpeg"></section></section></section><section powered-by="xiumi.us"><section><img data-ratio="0.24537037037037038" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66ia7QDJLgwvG7n6VBU0kwiaOzsPmPia2xsegedbhp18FjwuDILCIfv5r1xh0xRqAibrNT5gpAutaKyyUA/640?wx_fmt=jpeg" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66ia7QDJLgwvG7n6VBU0kwiaOzsPmPia2xsegedbhp18FjwuDILCIfv5r1xh0xRqAibrNT5gpAutaKyyUA/640?wx_fmt=jpeg"></section></section><section powered-by="xiumi.us"><section><img data-ratio="0.1638888888888889" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hOuC4CDbz41JswsKHVHPGNibiaOOEsvZiaD3ntdf7ABYPq3Cb5UKAo5gpia5ae1GvlEdH8ZRRtAGGUwQ/640?wx_fmt=png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hOuC4CDbz41JswsKHVHPGNibiaOOEsvZiaD3ntdf7ABYPq3Cb5UKAo5gpia5ae1GvlEdH8ZRRtAGGUwQ/640?wx_fmt=png"></section></section><a title="https://mp.weixin.qq.com/s?__biz=MzI3MjQ4MDMyOQ==&amp;mid=2247510155&amp;idx=1&amp;sn=8ebfed357fb3c2dd8ad5fdebf07ab803&amp;scene=21#wechat_redirect" formlinkparm='[{"href":"https://mp.weixin.qq.com/s?__biz=MzI3MjQ4MDMyOQ==&amp;mid=2247510155&amp;idx=1&amp;sn=8ebfed357fb3c2dd8ad5fdebf07ab803&amp;scene=21#wechat_redirect"}]' href="https://mp.weixin.qq.com/s?__biz=MzI3MjQ4MDMyOQ==&amp;mid=2247510155&amp;idx=1&amp;sn=8ebfed357fb3c2dd8ad5fdebf07ab803&amp;scene=21#wechat_redirect" target="_blank" rel="noopener noreferrer" powered-by="xiumi.us" data-linktype="1"><section><section><span><img data-ratio="0.30092592592592593" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66hRPKYJ3JticN69eUd5BOzbIqhXbs6um19njibgVHlv5uvncwro9uictKia9ZDlPsEBjwrvS91Xoy8JUQ/640?wx_fmt=jpeg" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66hRPKYJ3JticN69eUd5BOzbIqhXbs6um19njibgVHlv5uvncwro9uictKia9ZDlPsEBjwrvS91Xoy8JUQ/640?wx_fmt=jpeg"></span></section></section></a><a title="https://mp.weixin.qq.com/s?__biz=MzI3MjQ4MDMyOQ==&amp;mid=2247510670&amp;idx=1&amp;sn=d89c8031b181a60543919ab32c00300b&amp;scene=21#wechat_redirect" formlinkparm='[{"href":"https://mp.weixin.qq.com/s?__biz=MzI3MjQ4MDMyOQ==&amp;mid=2247510670&amp;idx=1&amp;sn=d89c8031b181a60543919ab32c00300b&amp;scene=21#wechat_redirect"}]' href="https://mp.weixin.qq.com/s?__biz=MzI3MjQ4MDMyOQ==&amp;mid=2247510670&amp;idx=1&amp;sn=d89c8031b181a60543919ab32c00300b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener noreferrer" powered-by="xiumi.us" data-linktype="1"><section><section><span><img data-ratio="0.30092592592592593" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHlYv1NGVXywUYg5wb2wtrGQqrmPnHvejHyicWJW5jgknxuBfT8w8da2w/640?wx_fmt=jpeg" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66jzibItV1aBxMXLy7VTGicNSHlYv1NGVXywUYg5wb2wtrGQqrmPnHvejHyicWJW5jgknxuBfT8w8da2w/640?wx_fmt=jpeg"></span></section></section></a><a title="https://mp.weixin.qq.com/s?__biz=MzI3MjQ4MDMyOQ==&amp;mid=2247510293&amp;idx=1&amp;sn=7b363caf423bf9650be47987ea3f3311&amp;scene=21#wechat_redirect" formlinkparm='[{"href":"https://mp.weixin.qq.com/s?__biz=MzI3MjQ4MDMyOQ==&amp;mid=2247510293&amp;idx=1&amp;sn=7b363caf423bf9650be47987ea3f3311&amp;scene=21#wechat_redirect"}]' href="https://mp.weixin.qq.com/s?__biz=MzI3MjQ4MDMyOQ==&amp;mid=2247510293&amp;idx=1&amp;sn=7b363caf423bf9650be47987ea3f3311&amp;scene=21#wechat_redirect" target="_blank" rel="noopener noreferrer" powered-by="xiumi.us" data-linktype="1"><section><section><span><img data-ratio="0.30092592592592593" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66hOuC4CDbz41JswsKHVHPGNeibRaib8iaVogfpSweOBQ1yVOAv3K0cXUibRQl7jOUe3tdBz4Bh1BWW5Lw/640?wx_fmt=jpeg" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66hOuC4CDbz41JswsKHVHPGNeibRaib8iaVogfpSweOBQ1yVOAv3K0cXUibRQl7jOUe3tdBz4Bh1BWW5Lw/640?wx_fmt=jpeg"></span></section></section></a><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><section><section powered-by="xiumi.us"><section><svg viewbox="0 0 1 1"></svg></section></section><section powered-by="xiumi.us"><section><svg viewbox="0 0 1 1"></svg></section></section></section><section><section powered-by="xiumi.us"><section><svg viewbox="0 0 1 1"></svg></section></section></section></section></section></section></section><section powered-by="xiumi.us"><section><section powered-by="xiumi.us"><section><p><strong><span>关于TCCI</span></strong></p></section></section></section></section><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><section><section powered-by="xiumi.us"><section><svg viewbox="0 0 1 1"></svg></section></section><section powered-by="xiumi.us"><section><svg viewbox="0 0 1 1"></svg></section></section></section></section></section></section></section></section></section></section><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><section><section powered-by="xiumi.us"><section><p><span>天桥脑科学研究院（Tianqiao and Chrissy Chen Institute，TCCI）是由陈天桥、雒芊芊夫妇私人出资10亿美元创建的，旨在聚焦AI＋脑科学，支持、推进全球范围内脑科学研究，造福全人类，目前已经成为知名的支持人类脑科学研究的科研机构。</span></p><p><br></p><p>TCCI一期投入5亿元人民币支持中国的脑科学研究，与上海周良辅医学发展基金会合作成立上海陈天桥脑健康研究所（又名TCCI转化中心），致力于提升脑健康和脑疾病治疗研究和成果转化。后又与华山医院、上海市精神卫生中心等建立战略合作，设立了应用神经技术前沿实验室、人工智能与精神健康前沿实验室。在国际上，TCCI与加州理工学院合作成立TCCI加州理工研究院，设脑机接口、社交与决策神经科学、系统神经科学、分子与细胞神经科学、大脑成像、神经科学教育等多个中心，重点关注大脑基础研究。TCCI还在北美、亚洲、欧洲、大洋洲主办、资助了200多场高质量的学术会议。</p></section></section></section></section></section></section></section><section powered-by="xiumi.us"><section><img data-ratio="0.6277777777777778" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66hOuC4CDbz41JswsKHVHPGN03TfCBxbPtw5FHKPZRSzRdvRx9dBftcatwLkicN1SAicX30ibkW2uuDDw/640?wx_fmt=jpeg" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nia5k43LG66hOuC4CDbz41JswsKHVHPGN03TfCBxbPtw5FHKPZRSzRdvRx9dBftcatwLkicN1SAicX30ibkW2uuDDw/640?wx_fmt=jpeg"></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><section powered-by="xiumi.us"><section><p><strong>追问互动</strong></p></section></section></section></section><section><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><section><section powered-by="xiumi.us"><section><svg viewbox="0 0 1 1"></svg></section></section></section><section><section powered-by="xiumi.us"><section><svg viewbox="0 0 1 1"></svg></section></section></section><section><section powered-by="xiumi.us"><section><svg viewbox="0 0 1 1"></svg></section></section></section></section></section></section></section></section></section></section></section></section></section><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><section><p><span><strong>○ </strong></span><strong>如果您对本期内容有进一步想要追问的问题或者讨论的内容，欢迎在评论区留言，或者扫描二维码添加追问微信号，发送自我介绍，加入我们的社群参与互动。如需转载，还请留言。</strong></p></section></section><section powered-by="xiumi.us"><section><section><img data-ratio="0.8388888888888889" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hElVgu2mTkwXlbBia4zqvaToHvUX1icQqo5pnkxxQ8JMpUGIwTfaJB3AvQr033veSPyUkZeNjVF4hg/640?wx_fmt=png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hElVgu2mTkwXlbBia4zqvaToHvUX1icQqo5pnkxxQ8JMpUGIwTfaJB3AvQr033veSPyUkZeNjVF4hg/640?wx_fmt=png"></section></section></section></section></section></section></section></section></section></section><section powered-by="xiumi.us"><section><img data-ratio="1.4814814814814814" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hOuC4CDbz41JswsKHVHPGNjyewdCzl4mXUYHxd17lbNGfWRoulDZCIpdbkS0ia0piag1hU3XLcMOjw/640?wx_fmt=png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/nia5k43LG66hOuC4CDbz41JswsKHVHPGNjyewdCzl4mXUYHxd17lbNGfWRoulDZCIpdbkS0ia0piag1hU3XLcMOjw/640?wx_fmt=png"></section></section></section><p><mp-style-type data-value="10000"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/YnO9IeNfvqcJq4gcNWaxeA",target="_blank" rel="noopener noreferrer">原文链接</a>
